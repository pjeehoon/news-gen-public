"""
Copyright (c) 2025 pjeehoon and KONA Project Contributors
This file is part of KONA (Korean Open News by AI).
Unauthorized commercial use is prohibited.
See LICENSE file for details.
"""

"""
ìŠ¤ë§ˆíŠ¸ ê¸°ì‚¬ ìƒì„± ì‹œìŠ¤í…œ
- ê¸°ì¡´ ê¸°ì‚¬ ì¬ì‚¬ìš©
- ìƒˆë¡œìš´ ì •ë³´ë§Œ ì—…ë°ì´íŠ¸
- ì¤‘ë³µ ë°©ì§€
"""

import json
import logging
from datetime import datetime, timezone
import os
import sys
import re
from typing import Dict, List, Optional, Any, Tuple
import markdown

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì‹¤í–‰ë˜ë„ë¡ ê²½ë¡œ ì„¤ì •
from pathlib import Path

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from scripts.path_utils import get_output_dir, get_smart_articles_dir, ensure_output_dirs
from scripts.article_cache_manager import ArticleCacheManager
from scripts.article_version_manager import ArticleVersionManager
from scripts.realtime_trend_analyzer import RealtimeTrendAnalyzer
from scripts.multi_article_deep_analyzer import MultiArticleDeepAnalyzer
from scripts.token_tracker import TokenTracker
from scripts.utils import APIKeyManager, RateLimiter, clean_text, truncate_text, get_kst_now, KST
from scripts.article_quality_evaluator import ArticleQualityEvaluator
from scripts.image_generator import generate_news_image
import openai
from dotenv import load_dotenv

load_dotenv()

# setup_logging ì‚¬ìš©í•˜ì—¬ ë¡œê¹… í‘œì¤€í™”
from scripts.utils import setup_logging

logger = setup_logging("smart_article_generator")


class SmartArticleGenerator:
    """
    ìŠ¤ë§ˆíŠ¸ ê¸°ì‚¬ ìƒì„± ì‹œìŠ¤í…œ
    
    ê¸°ì¡´ ê¸°ì‚¬ë¥¼ ì¬ì‚¬ìš©í•˜ê³  ìƒˆë¡œìš´ ì •ë³´ë§Œ ì—…ë°ì´íŠ¸í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ê¸°ì‚¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    í† í° ì‚¬ìš©ëŸ‰ì„ ì¶”ì í•˜ê³ , ì¤‘ë³µì„ ë°©ì§€í•˜ë©°, ë²„ì „ ê´€ë¦¬ë¥¼ í†µí•´ ê¸°ì‚¬ì˜ ì§„í™”ë¥¼ ì¶”ì í•©ë‹ˆë‹¤.
    
    Attributes:
        cache_manager: ê¸°ì‚¬ ìºì‹œ ê´€ë¦¬ì
        version_manager: ê¸°ì‚¬ ë²„ì „ ê´€ë¦¬ì
        trend_analyzer: ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë¶„ì„ê¸°
        article_analyzer: ë‹¤ì¤‘ ê¸°ì‚¬ ì‹¬ì¸µ ë¶„ì„ê¸°
        token_tracker: í† í° ì‚¬ìš©ëŸ‰ ì¶”ì ê¸°
        model_name: ì‚¬ìš©í•  AI ëª¨ë¸ëª…
    """

    def __init__(self) -> None:
        """SmartArticleGenerator ì´ˆê¸°í™”. í•„ìš”í•œ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ì™€ API í´ë¼ì´ì–¸íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
        self.cache_manager = ArticleCacheManager()
        self.version_manager = ArticleVersionManager()
        self.trend_analyzer = RealtimeTrendAnalyzer()
        self.article_analyzer = MultiArticleDeepAnalyzer()
        self.token_tracker = TokenTracker()
        self.quality_evaluator = ArticleQualityEvaluator()

        # API Key Manager ì‚¬ìš©
        self.api_manager = APIKeyManager()
        if not self.api_manager.has_valid_key():
            raise ValueError("No valid API key found")

        self.client = openai.OpenAI(api_key=self.api_manager.get_active_key())
        self.rate_limiter = RateLimiter(calls_per_minute=20)  # OpenAI rate limit

        # ëª¨ë¸ëª…ì„ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        self.model_name = os.getenv("DETAIL_MODEL", "gpt-4.1-nano")
        logger.info(f"Using model: {self.model_name}")

        self.total_tokens_used = 0
        self.total_cost = 0

    def sanitize_exclusive_terms(self, text: str) -> str:
        """
        ë…ì  ë³´ë„ ê´€ë ¨ í‘œí˜„ ì œê±°
        
        ë‰´ìŠ¤ ì œëª©ì´ë‚˜ ë³¸ë¬¸ì—ì„œ [ë‹¨ë…], [ì†ë³´] ë“±ì˜ ë…ì ì  í‘œí˜„ì„ ì œê±°í•©ë‹ˆë‹¤.
        
        Args:
            text: ì²˜ë¦¬í•  í…ìŠ¤íŠ¸
            
        Returns:
            ë…ì  ê´€ë ¨ í‘œí˜„ì´ ì œê±°ëœ í…ìŠ¤íŠ¸
        """
        # ì œê±°í•  í‘œí˜„ë“¤
        exclusive_terms = [
            "[ë‹¨ë…]",
            "ã€ë‹¨ë…ã€‘",
            "ã€ˆë‹¨ë…ã€‰",
            "ï¼œë‹¨ë…ï¼",
            "(ë‹¨ë…)",
            "[ë…ì ]",
            "ã€ë…ì ã€‘",
            "ã€ˆë…ì ã€‰",
            "ï¼œë…ì ï¼",
            "(ë…ì )",
            "[ì†ë³´]",
            "ã€ì†ë³´ã€‘",
            "ã€ˆì†ë³´ã€‰",
            "ï¼œì†ë³´ï¼",
            "(ì†ë³´)",
            "[ê¸´ê¸‰]",
            "ã€ê¸´ê¸‰ã€‘",
            "ã€ˆê¸´ê¸‰ã€‰",
            "ï¼œê¸´ê¸‰ï¼",
            "(ê¸´ê¸‰)",
            "[íŠ¹ì¢…]",
            "ã€íŠ¹ì¢…ã€‘",
            "ã€ˆíŠ¹ì¢…ã€‰",
            "ï¼œíŠ¹ì¢…ï¼",
            "(íŠ¹ì¢…)",
            "ë‹¨ë…:",
            "ë…ì :",
            "ì†ë³´:",
            "ê¸´ê¸‰:",
            "íŠ¹ì¢…:",
            "ë‹¨ë… -",
            "ë…ì  -",
            "ì†ë³´ -",
            "ê¸´ê¸‰ -",
            "íŠ¹ì¢… -",
            "ë‹¨ë…-",
            "ë…ì -",
            "ì†ë³´-",
            "ê¸´ê¸‰-",
            "íŠ¹ì¢…-",
            "<ë‹¨ë…>",
            "<ë…ì >",
            "<ì†ë³´>",
            "<ê¸´ê¸‰>",
            "<íŠ¹ì¢…>",
        ]

        # ë¨¼ì € clean_textë¡œ ê¸°ë³¸ ì •ë¦¬ (HTML íƒœê·¸ ì œê±°, ê³µë°± ì •ë¦¬ ë“±)
        result = clean_text(text)

        # ë…ì  ë³´ë„ ê´€ë ¨ í‘œí˜„ ì œê±°
        for term in exclusive_terms:
            result = result.replace(term, "").strip()

        # ë§¨ ì•ì— ì˜¤ëŠ” í•˜ì´í”ˆì´ë‚˜ ì½œë¡  ì œê±°
        result = re.sub(r"^[-:]\s*", "", result)

        return result.strip()

    def extract_keywords_from_title(self, title: str, article_content: str = None) -> List[str]:
        """
        ChatGPT APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì œëª©ê³¼ ë‚´ìš©ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
        
        ë‰´ìŠ¤ ì œëª©ê³¼ ì„ íƒì ìœ¼ë¡œ ë³¸ë¬¸ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ê³¼ íƒœê·¸ì—
        ìµœì í™”ëœ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            title: í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  ì œëª©
            article_content: ì„ íƒì  ê¸°ì‚¬ ë³¸ë¬¸ (ë” ì •í™•í•œ í‚¤ì›Œë“œ ì¶”ì¶œì„ ìœ„í•´)
            
        Returns:
            ì¶”ì¶œëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ 5ê°œ)
        """
        import json
        
        try:
            # ChatGPT APIë¥¼ ì‚¬ìš©í•œ ìŠ¤ë§ˆíŠ¸ í‚¤ì›Œë“œ ì¶”ì¶œ
            prompt = f"""
ë‹¤ìŒ ë‰´ìŠ¤ ì œëª©ì—ì„œ íƒœê·¸ì™€ ê²€ìƒ‰ì— ì‚¬ìš©í•  í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ì œëª©: {title}
{f'ë³¸ë¬¸ ìš”ì•½: {article_content[:300]}...' if article_content else ''}

ìš”êµ¬ì‚¬í•­:
1. íƒœê·¸ë¡œ ì‚¬ìš©í•˜ê¸° ì í•©í•œ í•µì‹¬ í‚¤ì›Œë“œ 5ê°œ
2. ì¸ë¬¼ëª…, ì§€ì—­ëª…, ì‚¬ê±´ëª…, í•µì‹¬ ì£¼ì œì–´ í¬í•¨
3. 2-4ê¸€ìì˜ ëª…í™•í•œ ë‹¨ì–´ ìœ„ì£¼
4. ì¤‘ë³µ ì—†ì´ ë‹¤ì–‘í•œ ê´€ì ì˜ í‚¤ì›Œë“œ

ì‘ë‹µ í˜•ì‹ (JSON):
{{
    "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3", "í‚¤ì›Œë“œ4", "í‚¤ì›Œë“œ5"]
}}
"""

            # Rate limiting ì ìš©
            self.rate_limiter.wait_if_needed()
            
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=200,
                response_format={
                    "type": "json_schema",
                    "json_schema": {
                        "name": "keywords_extraction",
                        "schema": {
                            "type": "object",
                            "properties": {
                                "keywords": {
                                    "type": "array",
                                    "items": {"type": "string"},
                                    "minItems": 5,
                                    "maxItems": 5,
                                    "description": "í•µì‹¬ í‚¤ì›Œë“œ 5ê°œ"
                                }
                            },
                            "required": ["keywords"],
                            "additionalProperties": False
                        },
                        "strict": True
                    }
                }
            )
            
            # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
            if hasattr(self, "current_article_id"):
                self.token_tracker.track_api_call(
                    response,
                    "gpt-4.1-nano",
                    self.current_article_id,
                    getattr(self, "current_article_title", None),
                )
            
            # ì‘ë‹µ íŒŒì‹±
            result = json.loads(response.choices[0].message.content)
            keywords = result.get("keywords", [])
            
            # ìœ íš¨í•œ í‚¤ì›Œë“œë§Œ í•„í„°ë§
            valid_keywords = [k.strip() for k in keywords if k.strip() and len(k.strip()) <= 20]
            
            logger.info(f"ChatGPTë¡œ ì¶”ì¶œëœ í‚¤ì›Œë“œ: {valid_keywords[:5]}")
            return valid_keywords[:5]
            
        except Exception as e:
            logger.error(f"ChatGPT í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            # í´ë°±: ê°„ë‹¨í•œ íŒ¨í„´ ê¸°ë°˜ ì¶”ì¶œ
            normalized_title = title.replace('"', "'").replace('"', "'").replace('"', "'")

            # ì£¼ìš” í‚¤ì›Œë“œ
            important_keywords = [
                "ì¥ê´€",
                "í›„ë³´",
                "ì§€ëª…",
                "ì² íšŒ",
                "ì„ëª…",
                "ì²­ë¬¸íšŒ",
                "ë…¼ë€",
                "ì˜í˜¹",
                "í­ìš°",
                "ì‚¬ê³ ",
                "í™”ì¬",
                "ëŒ€í†µë ¹",
                "ê°‘ì§ˆ",
            ]

            # ë‹¨ì–´ ë¶„ë¦¬
            words = normalized_title.split()

            for word in words:
                # ëì— ìˆëŠ” êµ¬ë‘ì  ì œê±°
                clean_word = word.rstrip(",.!?;:").strip()

                # ê´„í˜¸ë‚˜ ë”°ì˜´í‘œ ì œê±°
                clean_word = clean_word.strip("()[]{}\"'" "").strip()

                # ì¤‘ìš” í‚¤ì›Œë“œ ì²´í¬
                for kw in important_keywords:
                    if kw in clean_word and clean_word not in keywords:
                        keywords.append(clean_word)
                        break

            # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì¼ë°˜ì ì¸ ë‹¨ì–´ ì¶”ì¶œ
            if not keywords:
                words = normalized_title.split()
                keywords = [w.strip(",.!?;:()[]{}\"'" "") for w in words if len(w) > 2][:3]

            # ê¸°ë³¸ ë‹¨ì–´ ì¶”ì¶œ
            words = title.split()
            keywords = [w.strip(",.!?;:()[]{}\"'" "") for w in words if len(w) >= 3][:5]

        return keywords[:5]  # ìƒìœ„ 5ê°œë§Œ

    def generate_or_update_article(self, rank: int = 1) -> Dict[str, Any]:
        """
        ìŠ¤ë§ˆíŠ¸í•˜ê²Œ ê¸°ì‚¬ ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸
        
        íŠ¸ë Œë“œë¥¼ ë¶„ì„í•˜ì—¬ ì§€ì •ëœ ìˆœìœ„ì˜ ë‰´ìŠ¤ì— ëŒ€í•œ ê¸°ì‚¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        ê¸°ì¡´ ê´€ë ¨ ê¸°ì‚¬ê°€ ìˆë‹¤ë©´ ì—…ë°ì´íŠ¸í•˜ê³ , ì—†ë‹¤ë©´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            rank: ìƒì„±í•  ë‰´ìŠ¤ì˜ ìˆœìœ„ (1-10, ê¸°ë³¸ê°’: 1)
            
        Returns:
            ìƒì„±ëœ ê¸°ì‚¬ ì •ë³´ ë””í…ì…”ë„ˆë¦¬ (ìƒì„± ì‹¤íŒ¨ ì‹œ None)
            {
                "article_id": ê¸°ì‚¬ ID,
                "title": ì œëª©,
                "content": ë³¸ë¬¸,
                "url": ì›ë³¸ URL,
                "keywords": í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸,
                "created_at": ìƒì„± ì‹œê°„,
                "is_new": ìƒˆ ê¸°ì‚¬ ì—¬ë¶€,
                "status": ìƒíƒœ ë©”ì‹œì§€
            }
        """

        logger.info("=== ìŠ¤ë§ˆíŠ¸ ê¸°ì‚¬ ìƒì„± ì‹œì‘ ===")

        # 1. í˜„ì¬ íŠ¸ë Œë“œ ë¶„ì„
        logger.info("1ë‹¨ê³„: ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë¶„ì„")
        trends = self.trend_analyzer.analyze_realtime_trends()

        if not trends or not trends.get("hot_news"):
            logger.error("íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨")
            return None

        # ì§€ì •ëœ ìˆœìœ„ì˜ ë‰´ìŠ¤ ì„ íƒ
        if len(trends["hot_news"]) < rank:
            logger.warning(f"{rank}ìœ„ ë‰´ìŠ¤ê°€ ì—†ìŒ. 1ìœ„ë¡œ ëŒ€ì²´")
            rank = 1

        target_news = trends["hot_news"][rank - 1]
        title = self.sanitize_exclusive_terms(target_news["title"])  # ë…ì  ë³´ë„ í‘œí˜„ ì œê±°
        url = target_news["link"]
        category = target_news.get("category", None)  # ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¶”ì¶œ

        # í† í° ì¶”ì ì„ ìœ„í•œ article_id ì„¤ì •
        timestamp = get_kst_now().strftime("%Y%m%d_%H%M%S")
        self.current_article_id = f"article_{timestamp}"
        self.current_article_title = title

        logger.info(f"ëŒ€ìƒ ë‰´ìŠ¤: {title}")
        if category:
            logger.info(f"ì¹´í…Œê³ ë¦¬: {category}")

        # 2. ë¨¼ì € ì‹¬ì¸µ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì—¬ ì†ŒìŠ¤ ê¸°ì‚¬ URLë“¤ì„ ì–»ìŒ (í‚¤ì›Œë“œ ì¶”ì¶œì„ ìœ„í•´ ìˆœì„œ ë³€ê²½)
        logger.info("2ë‹¨ê³„: ì‹¬ì¸µ ë¶„ì„ìœ¼ë¡œ ì†ŒìŠ¤ ê¸°ì‚¬ ìˆ˜ì§‘")
        self.article_analyzer.token_tracker = self.token_tracker
        self.article_analyzer.current_article_id = self.current_article_id
        self.article_analyzer.current_article_title = self.current_article_title
        
        analysis_result = self.article_analyzer.analyze_topic(url, title, category)
        
        if not analysis_result:
            logger.error("ì‹¬ì¸µ ë¶„ì„ ì‹¤íŒ¨")
            return None
            
        # ì†ŒìŠ¤ ê¸°ì‚¬ URL ì¶”ì¶œ
        source_articles = analysis_result.get("source_articles", [])
        logger.info(f"ìˆ˜ì§‘ëœ ì†ŒìŠ¤ ê¸°ì‚¬: {len(source_articles)}ê°œ")
        
        # 3. ë¶„ì„ ê²°ê³¼ë¥¼ í™œìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
        article_content = analysis_result.get("comprehensive_article", "")
        keywords = self.extract_keywords_from_title(title, article_content)
        logger.info(f"ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")

        # 4. ë²„ì „ ê´€ë¦¬ìë¥¼ í†µí•œ ê´€ë ¨ ê¸°ì‚¬ í™•ì¸ (ì†ŒìŠ¤ ê¸°ì‚¬ ê¸°ë°˜ ìš°ì„ )
        logger.info("4ë‹¨ê³„: ê´€ë ¨ ê¸°ì‚¬ í™•ì¸ (ì†ŒìŠ¤ ê¸°ì‚¬ ê¸°ë°˜)")
        related_article_id = self.version_manager.find_related_article(
            title, keywords, new_source_articles=source_articles
        )

        if related_article_id:
            logger.info(f"ê´€ë ¨ ê¸°ì‚¬ ë°œê²¬: {related_article_id}")
            # ìºì‹œì—ì„œ ê¸°ì¡´ ê¸°ì‚¬ ë¡œë“œ
            existing_article = self.cache_manager.load_article(related_article_id)
            if existing_article:
                return self._handle_existing_article(
                    existing_article, title, url, keywords, related_article_id, category,
                    analysis_result=analysis_result, source_articles=source_articles
                )
            else:
                logger.warning(f"ê´€ë ¨ ê¸°ì‚¬ IDëŠ” ìˆì§€ë§Œ ìºì‹œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ: {related_article_id}")
                return self._create_new_article(title, url, keywords, category, 
                                              analysis_result=analysis_result, source_articles=source_articles)
        else:
            logger.info("ìƒˆë¡œìš´ ì£¼ì œ - ê¸°ì‚¬ ìƒì„± ì§„í–‰")
            return self._create_new_article(title, url, keywords, category,
                                          analysis_result=analysis_result, source_articles=source_articles)

    def generate_multiple_articles(self, start_rank: int = 1, end_rank: int = 5) -> Dict[str, Any]:
        """
        ì—¬ëŸ¬ ìˆœìœ„ì˜ ê¸°ì‚¬ë¥¼ í•œë²ˆì— ìƒì„± (ì¤‘ë³µ ë°©ì§€)
        
        ì§€ì •ëœ ë²”ìœ„ì˜ ìˆœìœ„ì— í•´ë‹¹í•˜ëŠ” ë‰´ìŠ¤ë“¤ì— ëŒ€í•´ ê¸°ì‚¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        ì´ë¯¸ ìƒì„±ëœ ê¸°ì‚¬ëŠ” ê±´ë„ˆë›°ì–´ ì¤‘ë³µì„ ë°©ì§€í•©ë‹ˆë‹¤.
        
        Args:
            start_rank: ì‹œì‘ ìˆœìœ„ (ê¸°ë³¸ê°’: 1)
            end_rank: ë ìˆœìœ„ (ê¸°ë³¸ê°’: 5)
            
        Returns:
            ìƒì„± ê²°ê³¼ ìš”ì•½ ë””í…ì…”ë„ˆë¦¬
            {
                "created": ìƒì„±ëœ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸,
                "skipped": ê±´ë„ˆë›´ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸,
                "failed": ì‹¤íŒ¨í•œ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸,
                "total_created": ìƒì„±ëœ ê¸°ì‚¬ ìˆ˜,
                "total_skipped": ê±´ë„ˆë›´ ê¸°ì‚¬ ìˆ˜,
                "total_failed": ì‹¤íŒ¨í•œ ê¸°ì‚¬ ìˆ˜
            }
        """

        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ¯ {start_rank}ìœ„~{end_rank}ìœ„ ê¸°ì‚¬ ì¼ê´„ ìƒì„± ì‹œì‘")
        logger.info(f"{'='*60}\n")

        results = {
            "created": [],
            "skipped": [],
            "failed": [],
            "total_created": 0,
            "total_skipped": 0,
            "total_failed": 0,
        }

        # íŠ¸ë Œë“œ ë¶„ì„ (í•œ ë²ˆë§Œ)
        logger.info("ğŸ“Š ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë¶„ì„ ì¤‘...")
        try:
            trends = self.trend_analyzer.analyze_realtime_trends()
            logger.info(f"íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼: {type(trends)}")

            if not trends:
                logger.error("âŒ íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨: trendsê°€ None")
                return results

            if not trends.get("hot_news"):
                logger.error(
                    f"âŒ íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨: hot_newsê°€ ì—†ìŒ. trends keys: {list(trends.keys())}"
                )
                return results

        except Exception as e:
            logger.error(f"âŒ íŠ¸ë Œë“œ ë¶„ì„ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}", exc_info=True)
            return results

        available_count = len(trends["hot_news"])
        logger.info(f"âœ… {available_count}ê°œì˜ íŠ¸ë Œë“œ ë‰´ìŠ¤ ë°œê²¬\n")

        # ì‹¤ì œ ì²˜ë¦¬í•  ë²”ìœ„ ì¡°ì •
        actual_end_rank = min(end_rank, available_count)

        # ê° ìˆœìœ„ì˜ ë‰´ìŠ¤ ì²˜ë¦¬
        for rank in range(start_rank, actual_end_rank + 1):
            logger.info(f"\n{'â”€'*50}")
            logger.info(f"ğŸ“° {rank}ìœ„ ë‰´ìŠ¤ ì²˜ë¦¬ ì¤‘...")

            target_news = trends["hot_news"][rank - 1]
            title = self.sanitize_exclusive_terms(target_news["title"])  # ë…ì  ë³´ë„ í‘œí˜„ ì œê±°
            url = target_news["link"]

            logger.info(f"ì œëª©: {title[:50]}...")

            # í‚¤ì›Œë“œ ì¶”ì¶œ (ì„ì‹œë¡œ ì œëª©ë§Œ ì‚¬ìš©)
            keywords = self.extract_keywords_from_title(title, None)
            logger.info(f"í‚¤ì›Œë“œ: {keywords}")

            # ê´€ë ¨ ê¸°ì‚¬ í™•ì¸
            related_article_id = self.version_manager.find_related_article(title, keywords)

            if related_article_id:
                # ê¸°ì¡´ ê¸°ì‚¬ê°€ ìˆëŠ” ê²½ìš°
                existing_article = self.cache_manager.load_article(related_article_id)
                if existing_article:
                    # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„ í™•ì¸ (ì—…ë°ì´íŠ¸ê°€ ìˆì—ˆë‹¤ë©´ ê·¸ ì‹œê°„, ì—†ìœ¼ë©´ ìƒì„± ì‹œê°„)
                    last_time = existing_article.get(
                        "last_updated", existing_article.get("created_at", "")
                    )
                    if last_time:
                        try:
                            # ISO format ë¬¸ìì—´ì„ íŒŒì‹±í•˜ê³  timezone ì²˜ë¦¬
                            if last_time.endswith("Z"):
                                last_datetime = datetime.fromisoformat(
                                    last_time.replace("Z", "+00:00")
                                )
                            else:
                                last_datetime = datetime.fromisoformat(last_time)

                            # timezoneì´ ì—†ìœ¼ë©´ UTCë¡œ ê°€ì •
                            if last_datetime.tzinfo is None:
                                last_datetime = last_datetime.replace(tzinfo=timezone.utc)

                            # í˜„ì¬ ì‹œê°„ë„ UTCë¡œ
                            current_time = datetime.now(KST)
                            time_diff = (current_time - last_datetime).total_seconds() / 3600

                            if time_diff < 1.0:  # 1ì‹œê°„ ì´ë‚´
                                logger.info(
                                    f"â­ï¸  ê±´ë„ˆëœ€: ë™ì¼ í† í”½ ê¸°ì‚¬ê°€ {time_diff:.1f}ì‹œê°„ ì „ì— ì‘ì„±/ì—…ë°ì´íŠ¸ë¨"
                                )
                                results["skipped"].append(
                                    {
                                        "rank": rank,
                                        "title": title,
                                        "reason": f"{time_diff:.1f}ì‹œê°„ ì „ ìƒì„±ëœ ë™ì¼ í† í”½",
                                        "existing_id": related_article_id,
                                    }
                                )
                                results["total_skipped"] += 1
                                continue
                        except Exception as e:
                            logger.debug(f"Created time parsing failed: {e}")

            # ìƒˆ ê¸°ì‚¬ ìƒì„±
            try:
                logger.info("âœï¸  ìƒˆ ê¸°ì‚¬ ìƒì„± ì¤‘...")
                result = self.generate_or_update_article(rank)

                if result and result["status"] in ["created", "updated"]:
                    if result["status"] == "created":
                        logger.info(f"âœ… ìƒì„± ì™„ë£Œ: {result.get('html_path', '')}")
                        results["created"].append(
                            {
                                "rank": rank,
                                "title": title,
                                "article_id": result.get("topic_id"),
                                "html_path": result.get("html_path"),
                            }
                        )
                        results["total_created"] += 1
                    else:  # updated
                        logger.info(
                            f"âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: {result.get('html_path', '')} (ë²„ì „ {result.get('version', 'N/A')})"
                        )
                        results["created"].append(
                            {
                                "rank": rank,
                                "title": title,
                                "article_id": result.get("topic_id"),
                                "html_path": result.get("html_path"),
                                "version": result.get("version"),
                            }
                        )
                        results["total_created"] += 1
                else:
                    logger.warning(f"âš ï¸  ìƒì„± ì‹¤íŒ¨ ë˜ëŠ” ì¬ì‚¬ìš©")
                    results["failed"].append(
                        {
                            "rank": rank,
                            "title": title,
                            "reason": (
                                result.get("message", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜") if result else "ìƒì„± ì‹¤íŒ¨"
                            ),
                        }
                    )
                    results["total_failed"] += 1

            except Exception as e:
                logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                results["failed"].append({"rank": rank, "title": title, "reason": str(e)})
                results["total_failed"] += 1

            # ì ì‹œ ëŒ€ê¸° (API ì œí•œ ê³ ë ¤)
            if rank < actual_end_rank:
                import time

                time.sleep(2)

        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        logger.info(f"\n{'='*60}")
        logger.info("ğŸ“Š ì¼ê´„ ìƒì„± ê²°ê³¼ ìš”ì•½")
        logger.info(f"{'='*60}")
        logger.info(f"âœ… ìƒì„±ë¨: {results['total_created']}ê°œ")
        logger.info(f"â­ï¸  ê±´ë„ˆëœ€: {results['total_skipped']}ê°œ")
        logger.info(f"âŒ ì‹¤íŒ¨: {results['total_failed']}ê°œ")

        if results["created"]:
            logger.info("\nâœ… ìƒì„±/ì—…ë°ì´íŠ¸ëœ ê¸°ì‚¬:")
            for item in results["created"]:
                if "version" in item:
                    logger.info(
                        f"  - {item['rank']}ìœ„: {item['title'][:40]}... (ë²„ì „ {item['version']})"
                    )
                else:
                    logger.info(f"  - {item['rank']}ìœ„: {item['title'][:40]}...")

        if results["skipped"]:
            logger.info("\nâ­ï¸  ê±´ë„ˆë›´ ê¸°ì‚¬:")
            for item in results["skipped"]:
                logger.info(f"  - {item['rank']}ìœ„: {item['title'][:40]}... ({item['reason']})")

        if results["failed"]:
            logger.info("\nâŒ ì‹¤íŒ¨í•œ ê¸°ì‚¬:")
            for item in results["failed"]:
                logger.info(f"  - {item['rank']}ìœ„: {item['title'][:40]}... ({item['reason']})")

        logger.info(f"\n{'='*60}\n")

        return results

    def _handle_existing_article(
        self,
        cached_data: Dict[str, Any],
        new_title: str,
        new_url: str,
        keywords: List[str],
        related_article_id: str,
        category: Optional[str] = None,
        analysis_result: Optional[Dict[str, Any]] = None,
        source_articles: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        """
        ê¸°ì¡´ ê¸°ì‚¬ ì²˜ë¦¬
        
        ê¸°ì¡´ì— ìƒì„±ëœ ê´€ë ¨ ê¸°ì‚¬ê°€ ìˆì„ ë•Œ, ìƒˆë¡œìš´ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ 
        í•„ìš”í•œ ê²½ìš° ì—…ë°ì´íŠ¸í•˜ê±°ë‚˜ ê¸°ì¡´ ê¸°ì‚¬ë¥¼ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.
        
        Args:
            cached_data: ìºì‹œëœ ê¸°ì¡´ ê¸°ì‚¬ ë°ì´í„°
            new_title: ìƒˆ ê¸°ì‚¬ ì œëª©
            new_url: ìƒˆ ê¸°ì‚¬ URL
            keywords: ì¶”ì¶œëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            related_article_id: ê´€ë ¨ ê¸°ì‚¬ ID
            category: ì¹´í…Œê³ ë¦¬ ì •ë³´ (ì„ íƒì‚¬í•­)
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë””í…ì…”ë„ˆë¦¬ (status: reused/updated)
        """

        topic_id = cached_data["topic_id"]
        logger.info(f"ê¸°ì¡´ ê¸°ì‚¬ ì²˜ë¦¬: {topic_id}")

        # ì†ŒìŠ¤ ê¸°ì‚¬ ê¸°ë°˜ ì—…ë°ì´íŠ¸ í•„ìš”ì„± í™•ì¸
        needs_update = False
        significant_changes = []
        
        if source_articles and cached_data.get("source_articles"):
            logger.info("ì†ŒìŠ¤ ê¸°ì‚¬ ê¸°ë°˜ ì—…ë°ì´íŠ¸ í™•ì¸")
            existing_sources = cached_data.get("source_articles", [])
            source_check = self.version_manager.check_update_necessity_by_sources(
                existing_sources, source_articles
            )
            
            if source_check["needs_update"]:
                needs_update = True
                significant_changes.append(source_check["reason"])
                logger.info(f"ìƒˆë¡œìš´ ì†ŒìŠ¤ ë°œê²¬: {len(source_check['new_sources'])}ê°œ")
            elif source_check["reason"] == "ëª¨ë“  ì†ŒìŠ¤ ê¸°ì‚¬ê°€ ë™ì¼í•¨":
                logger.info("ëª¨ë“  ì†ŒìŠ¤ê°€ ë™ì¼ - ì—…ë°ì´íŠ¸ ë¶ˆí•„ìš”")
                needs_update = False
        
        # ì†ŒìŠ¤ ê¸°ë°˜ í™•ì¸ì—ì„œ ì—…ë°ì´íŠ¸ê°€ ë¶ˆí•„ìš”í•˜ë‹¤ê³  íŒë‹¨ë˜ë©´ ê¸°ì¡´ ê¸°ì‚¬ ì¬ì‚¬ìš©
        if not needs_update and source_articles:
            # ì†ŒìŠ¤ê°€ ëª¨ë‘ ë™ì¼í•œ ê²½ìš°
            pass
        else:
            # ì†ŒìŠ¤ ê¸°ë°˜ í™•ì¸ì´ ì—†ê±°ë‚˜ ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•œ ê²½ìš° ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            logger.info("ì¶”ê°€ ì—…ë°ì´íŠ¸ í•„ìš”ì„± í™•ì¸")
            new_articles = self.article_analyzer.search_related_articles(new_title, limit=5)
            
            # ìƒˆë¡œìš´ ê¸°ì‚¬ ì •ë³´ ì¤€ë¹„
            new_article_data = {
                "title": new_title,
                "content": "\n".join([article.get("description", "") for article in new_articles]),
                "source_articles": source_articles or []
            }
            
            # ë²„ì „ ê´€ë¦¬ìë¥¼ í†µí•œ ì¶”ê°€ ì—…ë°ì´íŠ¸ í•„ìš”ì„± í™•ì¸
            additional_update, additional_changes = self.version_manager.check_update_necessity(
                cached_data, new_article_data
            )
            
            if additional_update:
                needs_update = True
                significant_changes.extend(additional_changes)

        if not needs_update:
            logger.info("ì¤‘ìš”í•œ ìƒˆë¡œìš´ ì •ë³´ ì—†ìŒ - ê¸°ì¡´ ê¸°ì‚¬ ì¬ì‚¬ìš©")

            # ê¸°ì‚¬ ë²„ì „ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
            version_history = self.version_manager.get_article_history(related_article_id)

            return {
                "status": "reused",
                "message": "ê¸°ì¡´ ê¸°ì‚¬ ì¬ì‚¬ìš© (ì¤‘ìš”í•œ ìƒˆë¡œìš´ ì •ë³´ ì—†ìŒ)",
                "article": cached_data.get(
                    "generated_article", cached_data.get("comprehensive_article", "")
                ),
                "topic_id": topic_id,
                "version": cached_data.get("version", 1),
                "last_updated": cached_data.get("last_updated", cached_data.get("created_at", "")),
                "version_history": version_history,
            }

        # ì¤‘ìš”í•œ ì—…ë°ì´íŠ¸ ìˆ˜í–‰
        logger.info(f"ì¤‘ìš”í•œ ìƒˆë¡œìš´ ì •ë³´ ë°œê²¬: {significant_changes}")

        # analysis_resultê°€ ì—†ìœ¼ë©´ ë¶„ì„ ìˆ˜í–‰
        if not analysis_result:
            logger.info("ì‹¬ì¸µ ë¶„ì„ ìˆ˜í–‰")
            self.article_analyzer.token_tracker = self.token_tracker
            self.article_analyzer.current_article_id = self.current_article_id
            self.article_analyzer.current_article_title = self.current_article_title
            
            # ë²„ì „ ì •ë³´ì™€ ì´ì „ ê¸°ì‚¬ ë‚´ìš© ì¤€ë¹„
            current_version = cached_data.get("version", 1) + 1  # ì—…ë°ì´íŠ¸ë  ë²„ì „
            previous_article_content = cached_data.get("comprehensive_article", "")
            
            analysis_result = self.article_analyzer.analyze_topic(
                new_url, new_title, category, 
                version=current_version,
                previous_article_content=previous_article_content
            )
            
            if not analysis_result:
                logger.error("ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ë¶„ì„ ì‹¤íŒ¨")
                return None

        # ì—…ë°ì´íŠ¸ ìˆ˜í–‰
        return self._update_existing_article_with_analysis(
            cached_data, analysis_result, related_article_id, significant_changes, source_articles
        )

    def _create_new_article(
        self, title: str, url: str, keywords: List[str], category: Optional[str] = None,
        analysis_result: Optional[Dict[str, Any]] = None, source_articles: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """ì™„ì „íˆ ìƒˆë¡œìš´ ê¸°ì‚¬ ìƒì„±"""

        # analysis_resultê°€ ì´ë¯¸ ì „ë‹¬ë˜ì—ˆë‹¤ë©´ ì¬ë¶„ì„í•˜ì§€ ì•ŠìŒ
        if analysis_result:
            logger.info("3ë‹¨ê³„: ì´ë¯¸ ìˆ˜í–‰ëœ ë¶„ì„ ê²°ê³¼ ì‚¬ìš©")
        else:
            # ë‹¤ì¤‘ ê¸°ì‚¬ ë¶„ì„
            logger.info("3ë‹¨ê³„: ë‹¤ì¤‘ ê¸°ì‚¬ ìˆ˜ì§‘ ë° ë¶„ì„")
            # í† í° ì¶”ì ì„ ìœ„í•œ ì •ë³´ ì „ë‹¬
            self.article_analyzer.token_tracker = self.token_tracker
            self.article_analyzer.current_article_id = self.current_article_id
            self.article_analyzer.current_article_title = self.current_article_title
            
            # ìƒˆ ê¸°ì‚¬ëŠ” ë²„ì „ 1ë¡œ ì‹œì‘
            analysis_result = self.article_analyzer.analyze_topic(
                url, title, category,
                version=1,
                previous_article_content=None
            )

        if not analysis_result:
            logger.error("ê¸°ì‚¬ ë¶„ì„ ì‹¤íŒ¨")
            return None

        # í’ˆì§ˆ í‰ê°€
        logger.info("4ë‹¨ê³„: ê¸°ì‚¬ í’ˆì§ˆ í‰ê°€")
        article_content = analysis_result["comprehensive_article"]
        
        # í’ˆì§ˆ í‰ê°€ ìˆ˜í–‰
        quality_rating, quality_emoji, quality_details = self.quality_evaluator.evaluate_article({
            "comprehensive_article": article_content,
            "generated_article": article_content
        })
        
        logger.info(f"ê¸°ì‚¬ í’ˆì§ˆ í‰ê°€ ê²°ê³¼: {quality_rating} {quality_emoji}")

        # íƒœê·¸ í™•ì¸ ë° ìƒì„±
        logger.info("5ë‹¨ê³„: ê¸°ì‚¬ ìµœì¢… ì²˜ë¦¬")
        tags = analysis_result.get("tags", {"category_tags": [], "content_tags": []})
        if not tags.get("category_tags") or not tags.get("content_tags"):
            logger.info("íƒœê·¸ê°€ ì—†ê±°ë‚˜ ë¶ˆì™„ì „í•¨. íƒœê·¸ ì¬ìƒì„± ì¤‘...")
            tags = self._generate_tags_for_article(title, article_content)

        # ìµœì¢… ê¸°ì‚¬ ë°ì´í„°
        final_article_data = {
            "main_article": analysis_result["main_article"],
            "generated_title": analysis_result.get("generated_title", title),  # AI ìƒì„± ì œëª© ì¶”ê°€
            "analysis": analysis_result["analysis"],
            "related_articles": analysis_result.get("related_articles", []),
            "comprehensive_article": article_content,  # Use the original article content
            "quality_rating": quality_rating,
            "quality_emoji": quality_emoji,
            "quality_details": quality_details,
            "youtube_count": analysis_result.get("youtube_count", 0),
            "google_count": analysis_result.get("google_count", 0),
            "youtube_videos": analysis_result.get("youtube_videos", []),
            "google_articles": analysis_result.get("google_articles", []),
            "tags": tags,  # ê²€ì¦ëœ íƒœê·¸
            "source_articles": analysis_result.get("source_articles", []),  # ì†ŒìŠ¤ ê¸°ì‚¬ URL ëª©ë¡
        }

        # ë²„ì „ ê´€ë¦¬ìë¥¼ í†µí•œ ê¸°ì‚¬ ìƒì„±
        article_data = {
            "title": title,
            "content": article_content,
            "keywords": keywords,
            "tags": tags,  # ê²€ì¦ëœ íƒœê·¸ ì‚¬ìš©
            "source_articles": analysis_result.get("source_articles", []),  # ì†ŒìŠ¤ ê¸°ì‚¬ URL ëª©ë¡
        }

        # ìƒˆ ê¸°ì‚¬ ID ìƒì„± (ë²„ì „ 1)
        article_id = self.version_manager.create_article_version(article_data)

        # ë²„ì „ íˆìŠ¤í† ë¦¬ ì¶”ê°€
        final_article_data["version"] = 1
        final_article_data["version_history"] = self.version_manager.get_article_history(article_id)

        # ìºì‹œ ì €ì¥ (ìƒˆë¡œìš´ ID ì‚¬ìš©)
        final_article_data["topic_id"] = article_id
        self.cache_manager.save_article_cache(final_article_data, keywords)
        
        # ì´ë¯¸ì§€ ìƒì„± (ë²„ì „ 1 ê¸°ì‚¬ë§Œ)
        logger.info("6ë‹¨ê³„: AI ì´ë¯¸ì§€ ìƒì„±")
        # ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¶”ê°€
        final_article_data["category"] = category  # ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¶”ê°€
        final_article_data["keywords"] = keywords  # í‚¤ì›Œë“œ ì •ë³´ ì¶”ê°€
        
        # ì„¸ ì¤„ ìš”ì•½ ì¶”ì¶œ (ì—†ìœ¼ë©´ ì²« ë¬¸ë‹¨ ì‚¬ìš©)
        if "three_line_summary" not in final_article_data:
            # article_contentì—ì„œ ì²« ë¬¸ë‹¨ ì¶”ì¶œ
            first_paragraph = article_content.split('\n\n')[0] if article_content else ""
            final_article_data["three_line_summary"] = first_paragraph[:200]  # ìµœëŒ€ 200ì
        
        image_result = generate_news_image(final_article_data)
        if image_result and image_result.get("success"):
            final_article_data["generated_image_path"] = image_result["image_path"]
            logger.info(f"ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {image_result['image_path']}")
            # ìºì‹œ ì—…ë°ì´íŠ¸
            self.cache_manager.save_article_cache(final_article_data, keywords)
        else:
            logger.warning(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {image_result.get('error', 'Unknown error') if image_result else 'No result'}")

        # HTML ìƒì„±
        html_output = self._generate_html(
            final_article_data, analysis_result.get("related_articles_count", 1)
        )

        # ê²°ê³¼ ì €ì¥
        ensure_output_dirs()
        output_dir = get_smart_articles_dir()

        timestamp = get_kst_now().strftime("%Y%m%d_%H%M%S")

        # ë²„ì „ë³„ íŒŒì¼ëª…
        version_filename = f"article_{article_id}_v{1}.html"
        version_path = f"{output_dir}/versions/{version_filename}"

        # ë²„ì „ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(f"{output_dir}/versions", exist_ok=True)

        # ë²„ì „ë³„ HTML ì €ì¥
        with open(version_path, "w", encoding="utf-8") as f:
            f.write(html_output)

        # ìµœì‹  ë²„ì „ ë§í¬ (ê¸°ì¡´ ë°©ì‹)
        html_path = f"{output_dir}/article_{timestamp}.html"
        with open(html_path, "w", encoding="utf-8") as f:
            f.write(html_output)

        logger.info(f"ìƒˆ ê¸°ì‚¬ ìƒì„± ì™„ë£Œ: {html_path}")
        logger.info(f"ë²„ì „ íŒŒì¼ ì €ì¥: {version_path}")

        return {
            "status": "created",
            "message": "ìƒˆë¡œìš´ ê¸°ì‚¬ ìƒì„± ì™„ë£Œ",
            "article": article_content,
            "topic_id": article_id,
            "version": 1,
            "html_path": html_path,
            # 'quality_scores': ì œê±°
            "version_history": final_article_data["version_history"],
        }

    def _update_existing_article_with_analysis(
        self,
        cached_data: Dict[str, Any],
        analysis_result: Dict[str, Any],
        related_article_id: str,
        significant_changes: List[str],
        source_articles: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¸°ì¡´ ê¸°ì‚¬ ì—…ë°ì´íŠ¸
        
        ìƒˆë¡œìš´ ë¶„ì„ ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ ê¸°ì‚¬ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        
        Args:
            cached_data: ìºì‹œëœ ê¸°ì¡´ ê¸°ì‚¬ ë°ì´í„°
            analysis_result: ìƒˆë¡œìš´ ë¶„ì„ ê²°ê³¼
            related_article_id: ê´€ë ¨ ê¸°ì‚¬ ID
            significant_changes: ì¤‘ìš”í•œ ë³€ê²½ì‚¬í•­ ë¦¬ìŠ¤íŠ¸
            source_articles: ì†ŒìŠ¤ ê¸°ì‚¬ URL ëª©ë¡
            
        Returns:
            ì—…ë°ì´íŠ¸ ê²°ê³¼ ë””í…ì…”ë„ˆë¦¬
        """
        
        # ìƒˆë¡œìš´ ê¸°ì‚¬ ë‚´ìš©
        updated_content = analysis_result["comprehensive_article"]
        
        # í’ˆì§ˆ ì¬í‰ê°€
        logger.info("ì—…ë°ì´íŠ¸ëœ ê¸°ì‚¬ í’ˆì§ˆ í‰ê°€ ì¤‘...")
        quality_rating, quality_emoji, quality_details = self.quality_evaluator.evaluate_article({
            "comprehensive_article": updated_content,
            "generated_article": updated_content
        })
        
        logger.info(f"ì—…ë°ì´íŠ¸ëœ ê¸°ì‚¬ í’ˆì§ˆ: {quality_rating} {quality_emoji}")
        
        # íƒœê·¸ í™•ì¸ ë° ìƒì„±
        tags = analysis_result.get("tags", {"category_tags": [], "content_tags": []})
        if not tags.get("category_tags") or not tags.get("content_tags"):
            logger.info("íƒœê·¸ ì¬ìƒì„± ì¤‘...")
            tags = self._generate_tags_for_article(
                cached_data["main_article"]["title"], updated_content
            )
        
        # ë²„ì „ ê´€ë¦¬ìë¥¼ í†µí•œ ìƒˆ ë²„ì „ ìƒì„±
        article_data = {
            "title": cached_data["main_article"]["title"],
            "content": updated_content,
            "keywords": cached_data.get("keywords", []),
            "significant_changes": significant_changes,
            "tags": tags,
            "source_articles": source_articles or [],  # ì†ŒìŠ¤ ê¸°ì‚¬ URL ì¶”ê°€
        }
        
        # ìƒˆ ë²„ì „ ID ìƒì„±
        new_article_id = self.version_manager.create_article_version(
            article_data, parent_id=related_article_id
        )
        
        # ìºì‹œ ì—…ë°ì´íŠ¸
        cached_data["generated_article"] = updated_content
        cached_data["comprehensive_article"] = updated_content
        cached_data["topic_id"] = new_article_id
        cached_data["version"] = self.version_manager.topic_index[new_article_id]["version"]
        cached_data["version_history"] = self.version_manager.get_article_history(new_article_id)
        cached_data["tags"] = tags
        cached_data["quality_rating"] = quality_rating
        cached_data["quality_emoji"] = quality_emoji
        cached_data["quality_details"] = quality_details
        cached_data["source_articles"] = source_articles or []  # ì†ŒìŠ¤ ê¸°ì‚¬ URL ì—…ë°ì´íŠ¸
        
        # ë¶„ì„ ê²°ê³¼ ì—…ë°ì´íŠ¸
        cached_data["analysis"] = analysis_result.get("analysis", {})
        cached_data["related_articles"] = analysis_result.get("related_articles", [])
        
        # ìƒˆ ë²„ì „ìœ¼ë¡œ ìºì‹œ ì €ì¥
        self.cache_manager.save_article_cache(cached_data, cached_data.get("keywords", []))
        
        # HTML ìƒì„± (ë²„ì „ íˆìŠ¤í† ë¦¬ í¬í•¨)
        html_output = self._generate_html(
            cached_data, 
            analysis_result.get("related_articles_count", 1), 
            is_update=True
        )
        
        # ê²°ê³¼ ì €ì¥
        ensure_output_dirs()
        output_dir = get_smart_articles_dir()
        
        # ë²„ì „ë³„ íŒŒì¼ëª…
        version_filename = f"article_{new_article_id}_v{cached_data['version']}.html"
        version_path = f"{output_dir}/versions/{version_filename}"
        
        # ë²„ì „ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(f"{output_dir}/versions", exist_ok=True)
        
        # ë²„ì „ë³„ HTML ì €ì¥
        with open(version_path, "w", encoding="utf-8") as f:
            f.write(html_output)
        
        logger.info(f"ì—…ë°ì´íŠ¸ëœ ê¸°ì‚¬ ì €ì¥: {version_path}")
        
        # ìµœì‹  ë²„ì „ ë§í¬ ì—…ë°ì´íŠ¸
        latest_filename = f"article_{new_article_id}_latest.html"
        latest_path = f"{output_dir}/{latest_filename}"
        with open(latest_path, "w", encoding="utf-8") as f:
            f.write(html_output)
        
        # JSON ë©”íƒ€ë°ì´í„° ì €ì¥
        json_filename = f"article_{new_article_id}.json"
        json_path = f"{output_dir}/{json_filename}"
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(cached_data, f, ensure_ascii=False, indent=2)
        
        return {
            "status": "updated",
            "message": f"ê¸°ì‚¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ (ë²„ì „ {cached_data['version']})",
            "significant_changes": significant_changes,
            "article": updated_content,
            "topic_id": new_article_id,
            "version": cached_data["version"],
            "version_history": cached_data["version_history"],
            "html_path": latest_path,
            "json_path": json_path,
        }

    def _update_existing_article(
        self,
        cached_data: Dict[str, Any],
        updates: Dict,
        new_articles: List[Dict],
        related_article_id: str,
        significant_changes: List[str],
    ) -> Dict[str, Any]:
        """
        ê¸°ì¡´ ê¸°ì‚¬ ì—…ë°ì´íŠ¸
        
        ì¤‘ìš”í•œ ìƒˆë¡œìš´ ì •ë³´ê°€ ë°œê²¬ë˜ì—ˆì„ ë•Œ ê¸°ì¡´ ê¸°ì‚¬ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        ìƒˆ ë²„ì „ì„ ìƒì„±í•˜ê³  ë²„ì „ íˆìŠ¤í† ë¦¬ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            cached_data: ìºì‹œëœ ê¸°ì¡´ ê¸°ì‚¬ ë°ì´í„°
            updates: ì—…ë°ì´íŠ¸í•  ë‚´ìš©
            new_articles: ìƒˆë¡œìš´ ê´€ë ¨ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
            related_article_id: ê´€ë ¨ ê¸°ì‚¬ ID
            significant_changes: ì¤‘ìš”í•œ ë³€ê²½ì‚¬í•­ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì—…ë°ì´íŠ¸ ê²°ê³¼ ë””í…ì…”ë„ˆë¦¬
        """

        # ìƒˆë¡œìš´ ì •ë³´ë¡œ ì¶”ê°€ ë¶„ì„
        new_analysis = {
            "new_developments": updates.get("new_developments", []),
            "updated_at": get_kst_now().isoformat(),
        }

        # ì—…ë°ì´íŠ¸ëœ ê¸°ì‚¬ ìƒì„±
        updated_content = self._generate_updated_content(
            cached_data["generated_article"], updates, new_articles
        )

        # í’ˆì§ˆ ì¬í‰ê°€
        logger.info("ì—…ë°ì´íŠ¸ëœ ê¸°ì‚¬ í’ˆì§ˆ í‰ê°€ ì¤‘...")
        quality_rating, quality_emoji, quality_details = self.quality_evaluator.evaluate_article({
            "comprehensive_article": updated_content,
            "generated_article": updated_content
        })
        
        logger.info(f"ì—…ë°ì´íŠ¸ëœ ê¸°ì‚¬ í’ˆì§ˆ: {quality_rating} {quality_emoji}")

        # ì—…ë°ì´íŠ¸ ì‹œì—ë„ íƒœê·¸ ì¬ìƒì„±
        logger.info("ê¸°ì‚¬ ì—…ë°ì´íŠ¸ ì‹œ íƒœê·¸ ì¬ìƒì„± ì¤‘...")
        updated_tags = self._generate_tags_for_article(
            cached_data["main_article"]["title"], updated_content
        )

        # ë²„ì „ ê´€ë¦¬ìë¥¼ í†µí•œ ìƒˆ ë²„ì „ ìƒì„±
        article_data = {
            "title": cached_data["main_article"]["title"],
            "content": updated_content,
            "keywords": cached_data.get("keywords", []),
            "significant_changes": significant_changes,
            "tags": updated_tags,  # ì—…ë°ì´íŠ¸ëœ íƒœê·¸ ì¶”ê°€
        }

        # ìƒˆ ë²„ì „ ID ìƒì„±
        new_article_id = self.version_manager.create_article_version(
            article_data, parent_id=related_article_id
        )

        # ìºì‹œ ì—…ë°ì´íŠ¸
        cached_data["generated_article"] = updated_content
        cached_data["comprehensive_article"] = updated_content
        cached_data["topic_id"] = new_article_id
        cached_data["version"] = self.version_manager.topic_index[new_article_id]["version"]
        cached_data["version_history"] = self.version_manager.get_article_history(new_article_id)
        cached_data["tags"] = updated_tags  # íƒœê·¸ë„ ì—…ë°ì´íŠ¸
        cached_data["quality_rating"] = quality_rating
        cached_data["quality_emoji"] = quality_emoji
        cached_data["quality_details"] = quality_details

        # ìƒˆ ë²„ì „ìœ¼ë¡œ ìºì‹œ ì €ì¥
        self.cache_manager.save_article_cache(cached_data, cached_data.get("keywords", []))

        updated_data = cached_data

        # HTML ìƒì„± (ë²„ì „ íˆìŠ¤í† ë¦¬ í¬í•¨)
        html_output = self._generate_html(updated_data, len(new_articles), is_update=True)

        # ê²°ê³¼ ì €ì¥
        ensure_output_dirs()
        output_dir = get_smart_articles_dir()
        timestamp = get_kst_now().strftime("%Y%m%d_%H%M%S")

        # ë²„ì „ë³„ íŒŒì¼ëª…
        version_filename = f"article_{new_article_id}_v{updated_data['version']}.html"
        version_path = f"{output_dir}/versions/{version_filename}"

        # ë²„ì „ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(f"{output_dir}/versions", exist_ok=True)

        # ë²„ì „ë³„ HTML ì €ì¥
        with open(version_path, "w", encoding="utf-8") as f:
            f.write(html_output)

        # ìµœì‹  ë²„ì „ ë§í¬ (ê¸°ì¡´ ë°©ì‹)
        html_path = f"{output_dir}/article_{timestamp}.html"
        with open(html_path, "w", encoding="utf-8") as f:
            f.write(html_output)

        logger.info(f"ê¸°ì‚¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {html_path} (ë²„ì „ {updated_data['version']})")
        logger.info(f"ë²„ì „ íŒŒì¼ ì €ì¥: {version_path}")

        return {
            "status": "updated",
            "message": f'ê¸°ì‚¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ (ë²„ì „ {updated_data["version"]})',
            "article": updated_content,
            "topic_id": new_article_id,
            "version": updated_data["version"],
            "html_path": html_path,
            "updates": updates,
            "significant_changes": significant_changes,
            "version_history": cached_data["version_history"],
        }

    def _generate_updated_content(
        self, original_article: str, updates: Dict, new_articles: List[Dict]
    ) -> str:
        """ì—…ë°ì´íŠ¸ëœ ê¸°ì‚¬ ë‚´ìš© ìƒì„±"""

        # í˜„ì¬ ë‚ ì§œ
        current_date = get_kst_now().strftime("%Yë…„ %mì›” %dì¼")

        # ìƒˆë¡œìš´ ì •ë³´ ìš”ì•½ (ì¶œì²˜ URL í¬í•¨)
        new_info_summary = []
        source_urls = []
        
        for dev in updates.get("new_developments", []):
            source = dev['source']
            url = dev.get('url', '')
            new_info_summary.append(f"- {source}: {dev.get('type', 'update')}")
            if url:
                source_urls.append(f"  - {source}: {url}")

        for fact in updates.get("new_facts", []):
            content_preview = fact['content_preview'][:100]
            url = fact.get('url', '')
            new_info_summary.append(f"- ìƒˆë¡œìš´ ì •ë³´: {content_preview}...")
            if url:
                source_urls.append(f"  - ìƒˆë¡œìš´ ì •ë³´ ì¶œì²˜: {url}")

        # ê´€ë ¨ ê¸°ì‚¬ URL ìˆ˜ì§‘
        article_sources = []
        for idx, article in enumerate(new_articles[:5]):  # ìµœëŒ€ 5ê°œê¹Œì§€
            title = article.get('title', f'ê¸°ì‚¬ {idx+1}')
            url = article.get('url', '')
            if url:
                article_sources.append(f"- [{title}]({url})")

        prompt = f"""
ë‹¤ìŒì€ ê¸°ì¡´ ê¸°ì‚¬ì…ë‹ˆë‹¤:

{original_article}

ë‹¤ìŒì€ ìƒˆë¡­ê²Œ ë°œê²¬ëœ ì •ë³´ì…ë‹ˆë‹¤:

{chr(10).join(new_info_summary)}

ì¶œì²˜ URL:
{chr(10).join(source_urls) if source_urls else '(URL ì •ë³´ ì—†ìŒ)'}

ê´€ë ¨ ê¸°ì‚¬ë“¤:
{chr(10).join(article_sources) if article_sources else '(ê´€ë ¨ ê¸°ì‚¬ ì—†ìŒ)'}

í˜„ì¬ ë‚ ì§œ: {current_date}

ìœ„ì˜ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ë°˜ì˜í•˜ì—¬ ê¸°ì‚¬ë¥¼ ì—…ë°ì´íŠ¸í•´ ì£¼ì„¸ìš”.

ì£¼ì˜ì‚¬í•­:
1. ê¸°ì¡´ ê¸°ì‚¬ì˜ ì£¼ìš” ë‚´ìš©ì€ ìœ ì§€í•˜ë˜, ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì ì ˆíˆ í†µí•©
2. ì—…ë°ì´íŠ¸ëœ ë¶€ë¶„ì€ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë‚´ê¸°
3. ì‹œê°„ ìˆœì„œë¥¼ ëª…í™•íˆ í•˜ì—¬ ë…ìê°€ ì‚¬ê±´ì˜ ì§„í–‰ì„ ì´í•´í•  ìˆ˜ ìˆë„ë¡
4. ë‚ ì§œëŠ” êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ (YYYYë…„ MMì›” DDì¼)
5. ê¸°ì‚¬ ëì— "(ìµœì¢… ì—…ë°ì´íŠ¸: {current_date})" ì¶”ê°€
6. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„± (### ì†Œì œëª©, [ë§í¬í…ìŠ¤íŠ¸](URL) ë“±)
7. [ë‹¨ë…], [ë…ì ], [ì†ë³´], [ê¸´ê¸‰], [íŠ¹ì¢…] ë“±ì˜ ë…ì  ë³´ë„ í‘œí˜„ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
8. **ì¤‘ìš”í•œ ì •ë³´ë‚˜ íŠ¹ë³„í•œ ì§„ìˆ ì— ëŒ€í•´ì„œëŠ” ë³¸ë¬¸ ë‚´ì— ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì›ë³¸ ê¸°ì‚¬ ë§í¬ë¥¼ ì§ì ‘ ì‚½ì…**
   ì˜ˆ: "ì •ë¶€ëŠ” [2025ë…„ 7ì›” 23ì¼ ë°œí‘œ](https://example.com/news/123)ì—ì„œ ìƒˆë¡œìš´ ì •ì±…ì„ ê³µê°œí–ˆë‹¤."
9. ìƒˆë¡­ê²Œ ì¶”ê°€ëœ ì¤‘ìš” ì •ë³´ëŠ” ì¶œì²˜ ë§í¬ì™€ í•¨ê»˜ ëª…ì‹œ

ì—…ë°ì´íŠ¸ëœ ê¸°ì‚¬ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

        try:
            # Rate limiting ì ìš©
            self.rate_limiter.wait_if_needed()

            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=3000,
            )

            # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
            if hasattr(self, "current_article_id"):
                self.token_tracker.track_api_call(
                    response,
                    self.model_name,
                    self.current_article_id,
                    getattr(self, "current_article_title", None),
                )

            return response.choices[0].message.content

        except Exception as e:
            logger.error(f"ê¸°ì‚¬ ì—…ë°ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return original_article

    def _refresh_article(
        self, cached_data: Dict[str, Any], new_title: str, new_url: str
    ) -> Dict[str, Any]:
        """
        ì˜¤ë˜ëœ ê¸°ì‚¬ ìƒˆë¡œê³ ì¹¨
        
        ì‘ì„±ëœì§€ ì˜¤ë˜ëœ ê¸°ì‚¬ì˜ ì‹œì œì™€ í‘œí˜„ì„ í˜„ì¬ ì‹œì ì— ë§ê²Œ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤.
        ê¸°ì‚¬ì˜ ë‚´ìš©ì€ ë™ì¼í•˜ê²Œ ìœ ì§€í•˜ë©´ì„œ í‘œí˜„ë§Œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        
        Args:
            cached_data: ìºì‹œëœ ê¸°ì¡´ ê¸°ì‚¬ ë°ì´í„°
            new_title: ìƒˆ ê¸°ì‚¬ ì œëª© (ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)
            new_url: ìƒˆ ê¸°ì‚¬ URL (ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)
            
        Returns:
            ìƒˆë¡œê³ ì¹¨ ê²°ê³¼ ë””í…ì…”ë„ˆë¦¬
        """

        # ê¸°ì¡´ ë¶„ì„ ë°ì´í„°ëŠ” ìœ ì§€í•˜ë©´ì„œ í‘œí˜„ë§Œ ìƒˆë¡œê³ ì¹¨
        prompt = f"""
ë‹¤ìŒì€ {cached_data['last_updated']}ì— ì‘ì„±ëœ ê¸°ì‚¬ì…ë‹ˆë‹¤:

{cached_data['generated_article']}

í˜„ì¬ ë‚ ì§œ: {get_kst_now().strftime("%Yë…„ %mì›” %dì¼")}

ìœ„ ê¸°ì‚¬ë¥¼ í˜„ì¬ ì‹œì ì— ë§ê²Œ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”.
- ë‚´ìš©ì€ ë™ì¼í•˜ê²Œ ìœ ì§€
- ì‹œì œì™€ í‘œí˜„ë§Œ í˜„ì¬ ìƒí™©ì— ë§ê²Œ ì¡°ì •
- ë‚ ì§œ í‘œí˜„ì„ êµ¬ì²´ì ìœ¼ë¡œ ìœ ì§€

ìƒˆë¡œê³ ì¹¨ëœ ê¸°ì‚¬ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

        try:
            # Rate limiting ì ìš©
            self.rate_limiter.wait_if_needed()

            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                max_tokens=3000,
            )

            refreshed_content = response.choices[0].message.content

            # í’ˆì§ˆ ì¬í‰ê°€ ì œê±°

            return {
                "status": "refreshed",
                "message": "ê¸°ì‚¬ ìƒˆë¡œê³ ì¹¨ ì™„ë£Œ",
                "article": refreshed_content,
                "topic_id": cached_data["topic_id"],
                "version": cached_data["version"],
                "last_updated": get_kst_now().isoformat(),
            }

        except Exception as e:
            logger.error(f"ê¸°ì‚¬ ìƒˆë¡œê³ ì¹¨ ì‹¤íŒ¨: {e}")
            return {
                "status": "reused",
                "message": "ê¸°ì¡´ ê¸°ì‚¬ ì¬ì‚¬ìš©",
                "article": cached_data["generated_article"],
                "topic_id": cached_data["topic_id"],
                "version": cached_data["version"],
            }

    def _generate_tags_for_article(self, title: str, content: str) -> Dict[str, Any]:
        """
        ê¸°ì‚¬ ì œëª©ê³¼ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ íƒœê·¸ ìƒì„±
        
        AIë¥¼ ì´ìš©í•˜ì—¬ ê¸°ì‚¬ì˜ ì¹´í…Œê³ ë¦¬ íƒœê·¸ì™€ ë‚´ìš© íƒœê·¸ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            title: ê¸°ì‚¬ ì œëª©
            content: ê¸°ì‚¬ ë³¸ë¬¸
            
        Returns:
            íƒœê·¸ ë””í…ì…”ë„ˆë¦¬ {
                "category_tags": [ì¹´í…Œê³ ë¦¬ íƒœê·¸ ë¦¬ìŠ¤íŠ¸],
                "content_tags": [ë‚´ìš© íƒœê·¸ ë¦¬ìŠ¤íŠ¸]
            }
        """
        try:
            prompt = f"""
ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì œëª©ê³¼ ë‚´ìš©ì„ ë³´ê³  íƒœê·¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ì œëª©: {title}

ë‚´ìš© (ì¼ë¶€):
{content[:1500]}

íƒœê·¸ëŠ” ë‘ ì¢…ë¥˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:

1. category_tags (ì¹´í…Œê³ ë¦¬ íƒœê·¸): ìµœëŒ€ 2ê°œ
   - ë‹¤ìŒ ì¤‘ì—ì„œë§Œ ì„ íƒ: ì •ì¹˜, ê²½ì œ, ì‚¬íšŒ, ìƒí™œ/ë¬¸í™”, êµ­ì œ, IT/ê³¼í•™

2. content_tags (ë‚´ìš© íƒœê·¸): 3-5ê°œ
   - ê¸°ì‚¬ì˜ í•µì‹¬ í‚¤ì›Œë“œ, ì¸ë¬¼ëª…, ê¸°ì—…ëª…, ì‚¬ê±´ëª… ë“±
   - ë„ˆë¬´ ì¼ë°˜ì ì¸ ë‹¨ì–´ë³´ë‹¤ëŠ” êµ¬ì²´ì ì¸ íƒœê·¸ ì„ í˜¸

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "category_tags": ["ì¹´í…Œê³ ë¦¬1", "ì¹´í…Œê³ ë¦¬2"],
    "content_tags": ["íƒœê·¸1", "íƒœê·¸2", "íƒœê·¸3"]
}}
"""

            # Rate limiting ì ìš©
            self.rate_limiter.wait_if_needed()

            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=200,
            )

            # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
            if hasattr(self, "current_article_id"):
                self.token_tracker.track_api_call(
                    response,
                    self.model_name,
                    self.current_article_id,
                    getattr(self, "current_article_title", None),
                )

            # JSON íŒŒì‹±
            response_text = response.choices[0].message.content.strip()
            # JSON ë¸”ë¡ ì¶”ì¶œ (```json ... ``` í˜•ì‹ ì²˜ë¦¬)
            if "```json" in response_text:
                response_text = response_text.split("```json")[1].split("```")[0].strip()
            elif "```" in response_text:
                response_text = response_text.split("```")[1].split("```")[0].strip()

            tags = json.loads(response_text)

            # ìœ íš¨ì„± ê²€ì‚¬ ë° ê¸°ë³¸ê°’ ì²˜ë¦¬
            if not isinstance(tags, dict):
                raise ValueError("Invalid tags format")

            # category_tags ê²€ì¦
            valid_categories = ["ì •ì¹˜", "ê²½ì œ", "ì‚¬íšŒ", "ìƒí™œ/ë¬¸í™”", "êµ­ì œ", "IT/ê³¼í•™"]
            category_tags = []
            for tag in tags.get("category_tags", []):
                if tag in valid_categories:
                    category_tags.append(tag)

            # ìµœì†Œ 1ê°œëŠ” ìˆì–´ì•¼ í•¨
            if not category_tags:
                # ì œëª©ì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ì¸¡
                if any(word in title for word in ["ëŒ€í†µë ¹", "êµ­íšŒ", "ì •ë¶€", "ì„ ê±°", "ì •ë‹¹"]):
                    category_tags = ["ì •ì¹˜"]
                elif any(word in title for word in ["ê²½ì œ", "ê¸ˆìœµ", "ì£¼ì‹", "ë¶€ë™ì‚°", "ê¸°ì—…"]):
                    category_tags = ["ê²½ì œ"]
                elif any(word in title for word in ["AI", "ì¸ê³µì§€ëŠ¥", "IT", "ê¸°ìˆ ", "ê³¼í•™"]):
                    category_tags = ["IT/ê³¼í•™"]
                else:
                    category_tags = ["ì‚¬íšŒ"]

            # content_tags ê²€ì¦
            content_tags = tags.get("content_tags", [])
            if not content_tags:
                # ì œëª©ê³¼ ë‚´ìš©ì—ì„œ ì£¼ìš” ë‹¨ì–´ ì¶”ì¶œ
                keywords = self.extract_keywords_from_title(title, comprehensive_article[:500])
                content_tags = keywords[:3] if keywords else ["ë‰´ìŠ¤"]

            return {
                "category_tags": category_tags[:2],  # ìµœëŒ€ 2ê°œ
                "content_tags": content_tags[:5],  # ìµœëŒ€ 5ê°œ
            }

        except Exception as e:
            logger.error(f"íƒœê·¸ ìƒì„± ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ íƒœê·¸ ë°˜í™˜
            return {
                "category_tags": ["ì‚¬íšŒ"],
                "content_tags": self.extract_keywords_from_title(title, None)[:3] or ["ë‰´ìŠ¤"],
            }

    def _generate_summary_section(self, article_data: Dict) -> str:
        """ì„¸ì¤„ ìš”ì•½ ë° í’ˆì§ˆ í‰ê°€ ì„¹ì…˜ ìƒì„± - ìš”ì•½ ì‹¤íŒ¨ ì‹œ ì„¹ì…˜ ìì²´ë¥¼ í‘œì‹œí•˜ì§€ ì•ŠìŒ"""
        summary = self._generate_three_line_summary(article_data)
        if summary is None:
            return ""  # ìš”ì•½ ìƒì„± ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
        
        # í’ˆì§ˆ í‰ê°€ ì •ë³´ëŠ” ê³„ì‚°í•˜ë˜ í‘œì‹œí•˜ì§€ ì•ŠìŒ
        # quality_rating = article_data.get("quality_rating", "")
        # quality_emoji = article_data.get("quality_emoji", "")
        # quality_section = ""
        
        # if quality_rating and quality_emoji:
        #     quality_section = f"""
        #     <div style="margin-top: 15px; padding: 10px; background: #f8f9fa; border-radius: 5px;">
        #         <strong>ì´ ê¸°ì‚¬ì˜ í’ˆì§ˆ:</strong> {quality_rating} {quality_emoji}
        #     </div>
        #     """

        return f"""
        <div class="meta">
            <h3>ğŸ“ ìš”ì•½</h3>
            {summary}
        </div>
        """

    def _generate_three_line_summary(self, article_data: Dict) -> str:
        """ê¸°ì‚¬ì˜ 3ì¤„ ìš”ì•½ ìƒì„±"""
        try:
            # ê¸°ì‚¬ ë‚´ìš© ì¶”ì¶œ
            article_content = article_data.get(
                "comprehensive_article", article_data.get("generated_article", "")
            )
            if not article_content:
                return None  # ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìœ¼ë©´ None ë°˜í™˜

            # OpenAI APIë¡œ 3ì¤„ ìš”ì•½ ìƒì„±
            prompt = f"""
ë‹¤ìŒ ê¸°ì‚¬ë¥¼ ì •í™•íˆ 3ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

ìš”ì•½ ê·œì¹™:
1. ë°˜ë“œì‹œ 3ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„± (ë” ë§ê±°ë‚˜ ì ìœ¼ë©´ ì•ˆë¨)
2. ê° ë¬¸ì¥ì€ í•µì‹¬ ì •ë³´ë¥¼ ë‹´ë˜, ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ
3. ì²« ì¤„: ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ ì‚¬ì‹¤
4. ë‘˜ ì§¸ ì¤„: ì£¼ìš” ì„¸ë¶€ì‚¬í•­ì´ë‚˜ ë°°ê²½
5. ì…‹ ì§¸ ì¤„: ì˜í–¥ì´ë‚˜ ì „ë§
6. ê° ì¤„ì€ ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±
7. ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ë‚˜ ê°ì •ì  í‘œí˜„ ì œê±°

ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "line1": "ì²« ë²ˆì§¸ ìš”ì•½ ë¬¸ì¥",
    "line2": "ë‘ ë²ˆì§¸ ìš”ì•½ ë¬¸ì¥",
    "line3": "ì„¸ ë²ˆì§¸ ìš”ì•½ ë¬¸ì¥"
}}

ê¸°ì‚¬ ë‚´ìš©:
{article_content[:2000]}
"""

            # Rate limiting ì ìš©
            self.rate_limiter.wait_if_needed()

            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "You must respond ONLY with valid JSON format. No other text or explanation."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=300,
                response_format={
                    "type": "json_schema",
                    "json_schema": {
                        "name": "three_line_summary",
                        "schema": {
                            "type": "object",
                            "properties": {
                                "line1": {
                                    "type": "string",
                                    "description": "ì²« ë²ˆì§¸ ìš”ì•½ ë¬¸ì¥"
                                },
                                "line2": {
                                    "type": "string",
                                    "description": "ë‘ ë²ˆì§¸ ìš”ì•½ ë¬¸ì¥"
                                },
                                "line3": {
                                    "type": "string",
                                    "description": "ì„¸ ë²ˆì§¸ ìš”ì•½ ë¬¸ì¥"
                                }
                            },
                            "required": ["line1", "line2", "line3"],
                            "additionalProperties": False
                        },
                        "strict": True
                    }
                }
            )

            # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
            if hasattr(self, "current_article_id"):
                self.token_tracker.track_api_call(
                    response,
                    self.model_name,
                    self.current_article_id,
                    getattr(self, "current_article_title", None),
                )

            summary = response.choices[0].message.content.strip()

            # JSON ì‘ë‹µ íŒŒì‹±
            try:
                import json
                summary_json = json.loads(summary)
                
                # JSONì—ì„œ 3ì¤„ ì¶”ì¶œ
                cleaned_lines = [
                    summary_json.get("line1", ""),
                    summary_json.get("line2", ""),
                    summary_json.get("line3", "")
                ]
                
                # ë¹ˆ ì¤„ ì²´í¬
                cleaned_lines = [line.strip() for line in cleaned_lines if line.strip()]
                
                # 3ì¤„ì´ ì•ˆ ë˜ì–´ë„ ìˆëŠ” ë§Œí¼ë§Œ ì‚¬ìš©
                    
            except (json.JSONDecodeError, ValueError) as e:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
                logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±: {e}")
                
                # ê¸°ì¡´ ë°©ì‹: ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬
                lines = summary.split("\n")
                lines = [line.strip() for line in lines if line.strip()]
                
                # ë¶ˆí•„ìš”í•œ ë²ˆí˜¸ë‚˜ ë§ˆì»¤ ì œê±°
                cleaned_lines = []
                for line in lines:
                    line = re.sub(r"^[\d]+\.\s*", "", line)
                    line = re.sub(r"^[-â€¢]\s*", "", line)
                    if line.strip():
                        cleaned_lines.append(line.strip())
                
                # 3ì¤„ì´ ì•ˆ ë˜ì–´ë„ ìˆëŠ” ë§Œí¼ë§Œ ì‚¬ìš©
                if len(cleaned_lines) == 0:
                    return "<p>ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.</p>"

            # HTML í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            html_summary = ""
            for i, line in enumerate(cleaned_lines[:3]):
                html_summary += f'<p style="margin: 8px 0;"><strong>{i+1}.</strong> {line}</p>\n'

            return html_summary

        except Exception as e:
            logger.error(f"3ì¤„ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return None  # ìš”ì•½ ìƒì„± ì‹¤íŒ¨ ì‹œ None ë°˜í™˜

    def _convert_markdown_to_html(self, text: str) -> str:
        """ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ë¥¼ HTMLë¡œ ë³€í™˜"""
        
        # Markdown ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì •
        # extensions:
        # - extra: í…Œì´ë¸”, ì½”ë“œ ë¸”ë¡, ê°ì£¼, ì•½ì–´, ì†ì„± ë¦¬ìŠ¤íŠ¸ ë“± ì¶”ê°€ ê¸°ëŠ¥
        # - nl2br: ì¤„ë°”ê¿ˆì„ <br> íƒœê·¸ë¡œ ë³€í™˜
        # - sane_lists: ë” ë‚˜ì€ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
        # - smarty: ìŠ¤ë§ˆíŠ¸ ë”°ì˜´í‘œ, ëŒ€ì‹œ ë“±
        md = markdown.Markdown(extensions=['extra', 'nl2br', 'sane_lists', 'smarty'])
        
        # ê¸°ì‚¬ ì œëª© ì²˜ë¦¬ë¥¼ ìœ„í•œ ì „ì²˜ë¦¬
        # ì²« ë²ˆì§¸ # ì œëª©ì„ ì°¾ì•„ì„œ h2ë¡œ ë³€í™˜í•˜ê³  ìŠ¤íƒ€ì¼ ì ìš©
        lines = text.split('\n')
        processed_lines = []
        article_title_found = False
        
        for line in lines:
            if line.startswith('# ') and not article_title_found:
                # ì²« ë²ˆì§¸ h1 ì œëª©ì€ ê±´ë„ˆë›°ê¸° (ì´ë¯¸ headerì— í‘œì‹œë¨)
                article_title_found = True
                continue  # ì´ ì¤„ì„ ê±´ë„ˆë›°ê³  ë‹¤ìŒ ì¤„ë¡œ
            else:
                processed_lines.append(line)
        
        # ë‹¤ì‹œ í•©ì¹˜ê¸°
        processed_text = '\n'.join(processed_lines)
        
        # Markdownì„ HTMLë¡œ ë³€í™˜
        html = md.convert(processed_text)
        
        # í›„ì²˜ë¦¬: ì™¸ë¶€ ë§í¬ì—ë§Œ target="_blank" ì¶”ê°€
        # ë‚´ë¶€ ë§í¬: /, #, /index.html, /article_xxx.html ë“±ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°
        # ì™¸ë¶€ ë§í¬: http://, https://, //ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°
        def add_target_blank(match):
            href = match.group(1)
            # ì™¸ë¶€ ë§í¬ì¸ ê²½ìš°ì—ë§Œ target="_blank" ì¶”ê°€
            if href.startswith(('http://', 'https://', '//')):
                return f'<a href="{href}" target="_blank">'
            else:
                return f'<a href="{href}">'
        
        html = re.sub(r'<a href="([^"]+)">', add_target_blank, html)
        
        # í›„ì²˜ë¦¬: ëª¨ë“  h2ë¥¼ h3ë¡œ ë³€ê²½ (ì²« ë²ˆì§¸ ì œëª©ì„ ì œê±°í–ˆìœ¼ë¯€ë¡œ)
        html = html.replace('<h2>', '<h3>').replace('</h2>', '</h3>')
        
        return html

    def _generate_html(
        self, article_data: Dict, related_count: int, is_update: bool = False
    ) -> str:
        """
        HTML ì¶œë ¥ ìƒì„±
        
        ê¸°ì‚¬ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì™„ì „í•œ HTML í˜ì´ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            article_data: ê¸°ì‚¬ ë°ì´í„° ë””í…ì…”ë„ˆë¦¬
            related_count: ê´€ë ¨ ê¸°ì‚¬ ìˆ˜
            is_update: ì—…ë°ì´íŠ¸ëœ ê¸°ì‚¬ì¸ì§€ ì—¬ë¶€
            
        Returns:
            ì™„ì „í•œ HTML ë¬¸ì„œ
        """

        # ê¸°ë³¸ í…œí”Œë¦¿
        current_time = get_kst_now().strftime("%Y-%m-%d %H:%M:%S")
        version_info = f"(ë²„ì „ {article_data.get('version', 1)})" if is_update else ""

        # comprehensive_articleì—ì„œ ì œëª© ì¶”ì¶œ
        # 1. ë¨¼ì € generated_titleì´ ìˆëŠ”ì§€ í™•ì¸ (ê°€ì¥ ìš°ì„ ìˆœìœ„)
        comprehensive_title = article_data.get('generated_title', None)
        
        # 2. generated_titleì´ ì—†ìœ¼ë©´ comprehensive_article ë‚´ìš©ì—ì„œ ì°¾ê¸°
        if not comprehensive_title:
            comprehensive_content = article_data.get('comprehensive_article', '')
            if comprehensive_content:
                # ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì—ì„œ ì²« ë²ˆì§¸ # ì œëª© ì°¾ê¸°
                import re
                title_match = re.search(r'^#\s+(.+?)$', comprehensive_content, re.MULTILINE)
                if title_match:
                    comprehensive_title = title_match.group(1).strip()
        
        # 3. ì—¬ì „íˆ ì œëª©ì„ ì°¾ì§€ ëª»í–ˆë‹¤ë©´ main_article ì œëª© ì‚¬ìš© (í´ë°±)
        if not comprehensive_title:
            comprehensive_title = article_data["main_article"]["title"]
        
        # ì œëª©ì—ì„œ ë…ì  ë³´ë„ í‘œí˜„ ì œê±°
        clean_title = self.sanitize_exclusive_terms(comprehensive_title)
        
        # íƒœê·¸ ì •ë³´ ì¶”ì¶œ
        tags = article_data.get("tags", {})
        category_tags = tags.get("category_tags", [])
        content_tags = tags.get("content_tags", [])
        all_tags = category_tags + content_tags

        html_template = f"""<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{clean_title} - {current_time}</title>
    <link rel="icon" type="image/svg+xml" href="/static/favicon.svg">
    <link rel="alternate icon" href="/static/favicon.svg">
    <meta name="article-tags" content="{','.join(all_tags)}">{f'''
    <meta name="article-category-tags" content="{','.join(category_tags)}">''' if category_tags else ''}{f'''
    <meta name="article-content-tags" content="{','.join(content_tags)}">''' if content_tags else ''}
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.8;
            background: #f5f5f5;
        }}
        .container {{
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        .header {{
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 30px;
        }}
        .version-badge {{
            background: #17a2b8;
            color: white;
            padding: 5px 15px;
            border-radius: 20px;
            display: inline-block;
            font-weight: bold;
            margin-bottom: 10px;
        }}
        .update-info {{
            background: #d4edda;
            border: 1px solid #c3e6cb;
            padding: 15px;
            border-radius: 5px;
            margin: 20px 0;
        }}
        .article-content {{
            margin: 30px 0;
            font-size: 17px;
            line-height: 1.9;
        }}
        .article-content h3 {{
            font-size: 1.4rem;
            color: #333;
            margin: 30px 0 15px 0;
            padding-bottom: 10px;
            border-bottom: 2px solid #e9ecef;
        }}
        .article-content p {{
            margin: 15px 0;
            text-align: justify;
        }}
        .meta {{
            margin: 20px 0;
            padding: 15px;
            background: #e9ecef;
            border-radius: 8px;
        }}
        .version-history {{
            margin: 30px 0;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 8px;
            border: 1px solid #dee2e6;
        }}
        .version-history h3 {{
            margin-top: 0;
            color: #495057;
            cursor: pointer;
            user-select: none;
            display: flex;
            align-items: center;
            justify-content: space-between;
        }}
        .version-history h3:hover {{
            color: #343a40;
        }}
        .version-toggle {{
            font-size: 0.9em;
            color: #6c757d;
            transition: transform 0.3s ease;
        }}
        .version-toggle.open {{
            transform: rotate(180deg);
        }}
        .version-list {{
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease;
        }}
        .version-list.open {{
            max-height: 500px;
            overflow-y: auto;
        }}
        .version-item {{
            margin: 10px 0;
            padding: 10px;
            background: white;
            border-radius: 4px;
            border-left: 3px solid #17a2b8;
        }}
        .version-item.current {{
            border-left-color: #28a745;
            font-weight: bold;
        }}
        .version-date {{
            font-size: 14px;
            color: #6c757d;
        }}
        .sources-section {{
            margin-top: 40px;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 8px;
            border: 1px solid #dee2e6;
        }}
        .sources-section h4 {{
            margin: 0 0 10px 0;
            font-size: 1.1rem;
            color: #495057;
        }}
        .source-list {{
            margin: 5px 0;
            font-size: 0.9rem;
        }}
        .source-list a {{
            color: #1a73e8;
            text-decoration: none;
            margin-right: 10px;
        }}
        .source-list a:hover {{
            text-decoration: underline;
        }}
        
        /* Floating Action Button */
        .fab {{
            position: fixed;
            bottom: 20px;
            right: 20px;
            width: 56px;
            height: 56px;
            background: #0066cc;
            color: white;
            border-radius: 28px;
            border: none;
            box-shadow: 0 2px 10px rgba(0,102,204,0.3);
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            text-decoration: none;
            font-size: 24px;
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 1000;
        }}
        
        .fab:hover {{
            transform: scale(1.1);
            box-shadow: 0 4px 20px rgba(0,102,204,0.4);
        }}
        
        /* Related Articles Section */
        .related-articles {{
            margin-top: 50px;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 8px;
            border: 1px solid #dee2e6;
        }}
        
        .related-articles h3 {{
            margin: 0 0 20px 0;
            color: #495057;
            font-size: 1.3rem;
        }}
        
        .related-article-item {{
            padding: 15px;
            margin-bottom: 10px;
            background: white;
            border-radius: 4px;
            border-left: 3px solid #0066cc;
            transition: transform 0.2s;
        }}
        
        .related-article-item:hover {{
            transform: translateX(5px);
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }}
        
        .related-article-item a {{
            color: #333;
            text-decoration: none;
            font-weight: 500;
        }}
        
        .related-article-item a:hover {{
            color: #0066cc;
        }}
        
        .related-article-meta {{
            font-size: 0.85rem;
            color: #6c757d;
            margin-top: 5px;
        }}
        
        .loading-message {{
            text-align: center;
            color: #6c757d;
            padding: 20px;
        }}
        
        /* Mobile responsiveness */
        @media (max-width: 768px) {{
            .fab {{
                bottom: 70px;
                right: 15px;
            }}
        }}
    </style>
    <script>
        function toggleVersionHistory() {{
            const versionList = document.querySelector('.version-list');
            const toggleIcon = document.querySelector('.version-toggle');
            
            if (versionList.classList.contains('open')) {{
                versionList.classList.remove('open');
                toggleIcon.classList.remove('open');
            }} else {{
                versionList.classList.add('open');
                toggleIcon.classList.add('open');
            }}
        }}
        
        // Load related articles based on current filter state
        async function loadRelatedArticles() {{
            const relatedSection = document.getElementById('related-articles-list');
            // current_time í˜•ì‹: 2025-07-24 02:00:29
            const [datePart, timePart] = '{current_time}'.split(' ');
            const [year, month, day] = datePart.split('-');
            const [hour, minute, second] = timePart.split(':');
            const currentDate = new Date(year, month-1, day, hour, minute, second);
            
            // console.log('Loading related articles...');
            // console.log('Current date:', currentDate);
            
            try {{
                // Get the current filter state from URL hash
                const hash = window.location.hash.slice(1);
                const filters = hash ? hash.split(',').map(tag => decodeURIComponent(tag)) : [];
                // console.log('Active filters:', filters);
                
                // Fetch the main index page to get all articles
                const response = await fetch('/index.html');
                const html = await response.text();
                const parser = new DOMParser();
                const doc = parser.parseFromString(html, 'text/html');
                
                // Find all article items
                const articles = doc.querySelectorAll('.article-card');
                //console.log('Found articles:', articles.length);
                const filteredArticles = [];
                
                articles.forEach(article => {{
                    const titleElement = article.querySelector('h2');
                    const title = titleElement?.textContent;
                    const link = article.getAttribute('href');
                    const dateElement = article.querySelector('.article-meta span');
                    const dateText = dateElement?.textContent?.replace('ğŸ“… ', '');
                    
                    // console.log('Processing article:', title, 'Date text:', dateText);
                    
                    // Skip the current article
                    if (title && title.includes('{clean_title}')) {{
                        // console.log('Skipping current article:', title);
                        return;
                    }}
                    
                    // Parse the article date
                    let articleDate = null;
                    if (dateText) {{
                        // ë‚ ì§œ í˜•ì‹: "2025ë…„ 07ì›” 24ì¼ 01:03"
                        const match = dateText.match(/(\\d{{4}})ë…„\\s+(\\d{{2}})ì›”\\s+(\\d{{2}})ì¼\\s+(\\d{{2}}):(\\d{{2}})/);
                        if (match) {{
                            articleDate = new Date(match[1], match[2]-1, match[3], match[4], match[5]);
                            // console.log('Parsed date:', articleDate);
                        }} else {{
                            // console.log('Date regex did not match for:', dateText);
                        }}
                    }}
                    
                    // Skip if no date found
                    if (!articleDate) {{
                        // console.log('Skipping article - no date found');
                        return;
                    }}
                    
                    // í˜„ì¬ ê¸°ì‚¬ë³´ë‹¤ ì˜¤ë˜ëœ ê¸°ì‚¬ë§Œ í‘œì‹œ
                    if (articleDate >= currentDate) {{
                        // console.log('Skipping newer or same-time article:', title);
                        return;
                    }}
                    
                    // If filters are applied, check if article matches
                    if (filters.length > 0) {{
                        const tagsData = article.getAttribute('data-tags');
                        if (!tagsData) return;
                        
                        const articleTags = tagsData.split('|').filter(tag => tag);
                        
                        const hasMatchingTag = filters.some(filter => articleTags.includes(filter));
                        if (!hasMatchingTag) return;
                    }}
                    
                    // Add the article to the list
                    if (title && link && dateText) {{
                        filteredArticles.push({{
                            title: title,
                            link: link,
                            date: dateText,
                            timestamp: articleDate
                        }});
                    }}
                }});
                
                // Sort by date (newest first among older articles)
                filteredArticles.sort((a, b) => b.timestamp - a.timestamp);
                
                // Display up to 10 articles
                if (filteredArticles.length > 0) {{
                    // Clear existing content
                    relatedSection.innerHTML = '';
                    
                    // Create articles using DOM methods to avoid CSP issues
                    filteredArticles.slice(0, 10).forEach(article => {{
                        const itemDiv = document.createElement('div');
                        itemDiv.className = 'related-article-item';
                        
                        const link = document.createElement('a');
                        link.href = article.link;
                        link.textContent = article.title;
                        
                        const metaDiv = document.createElement('div');
                        metaDiv.className = 'related-article-meta';
                        metaDiv.textContent = article.date;
                        
                        itemDiv.appendChild(link);
                        itemDiv.appendChild(metaDiv);
                        relatedSection.appendChild(itemDiv);
                    }});
                }} else {{
                    const message = document.createElement('p');
                    message.className = 'loading-message';
                    if (filters.length > 0) {{
                        message.textContent = 'ì„ íƒí•œ í•„í„°ì— í•´ë‹¹í•˜ëŠ” ì´ì „ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.';
                    }} else {{
                        message.textContent = 'ì´ì „ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.';
                    }}
                    relatedSection.innerHTML = '';
                    relatedSection.appendChild(message);
                }}
                
            }} catch (error) {{
                console.error('Error loading related articles:', error);
                const errorMessage = document.createElement('p');
                errorMessage.className = 'loading-message';
                errorMessage.textContent = 'ê¸°ì‚¬ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
                relatedSection.innerHTML = '';
                relatedSection.appendChild(errorMessage);
            }}
        }}
        
        // Load related articles when page loads
        document.addEventListener('DOMContentLoaded', loadRelatedArticles);
    </script>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>{clean_title}</h1>
            <p>
                ë¶„ì„ ì‹œê°„: {current_time}
                {f' <span style="font-size: 0.85rem; color: #17a2b8; margin-left: 15px;">âœ… ë²„ì „ {article_data.get("version", 1)} (ì—…ë°ì´íŠ¸ë¨)</span>' if is_update else ''}
            </p>
        </div>
        
        {self._generate_summary_section(article_data)}
        
        {self._generate_ai_image_section(article_data)}
        
        <div class="article-content">
{self._convert_markdown_to_html(article_data.get('comprehensive_article', article_data.get('generated_article', '')))}
        </div>
        
        {self._generate_version_history_html(article_data.get('version_history', []))}
        
        {self._generate_sources_section(article_data)}
        
        <!-- Related Articles Section -->
        <div class="related-articles">
            <h3>ğŸ“° ë‹¤ë¥¸ ê¸°ì‚¬</h3>
            <div id="related-articles-list">
                <p class="loading-message">ê¸°ì‚¬ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...</p>
            </div>
        </div>
        
        <hr>
        <p><small>ì´ ê¸°ì‚¬ëŠ” AIê°€ ìë™ìœ¼ë¡œ ìƒì„±í•˜ê³  ê´€ë¦¬í•˜ëŠ” ìŠ¤ë§ˆíŠ¸ ê¸°ì‚¬ì…ë‹ˆë‹¤.</small></p>
    </div>
    
    <!-- Floating Home Button -->
    <a href="/index.html" class="fab" title="í™ˆìœ¼ë¡œ">ğŸ </a>
</body>
</html>"""

        return html_template

    def _generate_version_history_html(self, version_history: List[Dict]) -> str:
        """ë²„ì „ íˆìŠ¤í† ë¦¬ HTML ìƒì„±"""
        if not version_history or len(version_history) <= 1:
            return ""  # ë²„ì „ì´ í•˜ë‚˜ë¿ì´ë©´ íˆìŠ¤í† ë¦¬ í‘œì‹œ ì•ˆ í•¨

        html = """
        <div class="version-history">
            <h3 onclick="toggleVersionHistory()">
                <span>ğŸ“š ê¸°ì‚¬ ì—…ë°ì´íŠ¸ íˆìŠ¤í† ë¦¬</span>
                <span class="version-toggle">â–¼</span>
            </h3>
            <div class="version-list">
                <p style="font-size: 14px; color: #6c757d; margin: 15px 0;">
                    ì´ ì£¼ì œì— ëŒ€í•œ ê¸°ì‚¬ê°€ ì‹œê°„ì— ë”°ë¼ ì–´ë–»ê²Œ ì—…ë°ì´íŠ¸ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
                </p>
        """

        # ë²„ì „ì„ ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_history = sorted(version_history, key=lambda x: x["version"], reverse=True)

        for version_info in sorted_history:
            is_current = version_info.get("is_current", False)
            version_class = "version-item current" if is_current else "version-item"

            # ë‚ ì§œ í¬ë§·íŒ…
            created_at = version_info.get("created_at", "")
            if created_at:
                try:
                    dt = datetime.fromisoformat(created_at)
                    formatted_date = dt.strftime("%Yë…„ %mì›” %dì¼ %H:%M")
                except Exception as e:
                    logger.debug(f"Date formatting failed: {e}")
                    formatted_date = created_at
            else:
                formatted_date = "ë‚ ì§œ ì •ë³´ ì—†ìŒ"

            # ë²„ì „ íŒŒì¼ ë§í¬ ìƒì„±
            article_id = version_info.get("article_id", "")
            version_num = version_info.get("version", "?")
            version_link = f"versions/article_{article_id}_v{version_num}.html"

            html += f"""
            <div class="{version_class}">
                <div style="display: flex; justify-content: space-between; align-items: center;">
                    <div>
                        <a href="{version_link}" target="_blank" style="text-decoration: none; color: inherit;">
                            <strong>ë²„ì „ {version_num}</strong>
                        </a>
                        {' (í˜„ì¬)' if is_current else ''}
                    </div>
                    <div class="version-date">{formatted_date}</div>
                </div>
                {f'<div style="margin-top: 5px; font-size: 14px;">{version_info.get("title", "")}</div>' if version_info.get('title') else ''}
                <div style="margin-top: 5px; font-size: 13px;">
                    <a href="{version_link}" target="_blank" style="color: #1a73e8; text-decoration: none;">
                        ì´ ë²„ì „ ë³´ê¸° â†’
                    </a>
                </div>
            </div>
            """

        html += """
            </div>
        </div>
        """

        return html

    def _generate_ai_image_section(self, article_data: Dict) -> str:
        """AI ìƒì„± ì´ë¯¸ì§€ ì„¹ì…˜ ìƒì„±"""
        # ìƒì„±ëœ ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
        image_path = article_data.get("generated_image_path")
        if not image_path:
            return ""
        
        # ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì›¹ ê²½ë¡œë¡œ ë³€í™˜
        web_image_path = f"/{image_path}"
        
        article_title = article_data.get("main_article", {}).get("title", "ë‰´ìŠ¤ ì´ë¯¸ì§€")
        
        ai_image_section = f"""
        <div class="ai-image-section" style="margin: 30px 0;">
            <div style="position: relative; overflow: hidden; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);">
                <img src="{web_image_path}" 
                     alt="{article_title}" 
                     style="width: 100%; height: auto; display: block; max-height: 500px; object-fit: cover;"
                     loading="lazy">
                <div style="position: absolute; top: 10px; left: 10px; background: rgba(0,0,0,0.8); color: white; padding: 5px 10px; border-radius: 4px; font-size: 0.85rem;">
                    ğŸ¨ AI ìƒì„± ì´ë¯¸ì§€
                </div>
            </div>
            <div style="margin-top: 10px; padding: 15px; background: #f8f9fa; border-radius: 8px;">
                <p style="margin: 0; font-size: 0.85rem; color: #666;">
                    â€» ì´ ì´ë¯¸ì§€ëŠ” ê¸°ì‚¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ AIê°€ ìƒì„±í•œ ì´ë¯¸ì§€ì…ë‹ˆë‹¤.
                </p>
            </div>
        </div>
        """
        
        return ai_image_section

    def _generate_sources_section(self, article_data: Dict) -> str:
        """ì°¸ì¡° ì†ŒìŠ¤ ì„¹ì…˜ HTML ìƒì„± (ë©”íƒ€ë°ì´í„° í¬í•¨)"""
        sources_html = ""
        has_sources = False

        # ì†ŒìŠ¤ ì„¹ì…˜ ì‹œì‘
        sources_html += """
        <div class="sources-section">"""
        has_sources = True

        # YouTube ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
        if "youtube_videos" in article_data and article_data["youtube_videos"]:
            sources_html += """
            <h4>ğŸ¥ ì°¸ì¡°í•œ YouTube ì˜ìƒ</h4>
            <div class="source-list">"""

            for video in article_data["youtube_videos"][:5]:  # ìµœëŒ€ 5ê°œ
                title = video.get("title", "")
                link = video.get("link", video.get("url", ""))  # link ë˜ëŠ” url í‚¤ ì‚¬ìš©
                if title and link:
                    # ì œëª©ì´ ë„ˆë¬´ ê¸¸ë©´ ì¤„ì„
                    display_title = title[:30] + "..." if len(title) > 30 else title
                    sources_html += f'<a href="{link}" target="_blank">{display_title}</a>'

            sources_html += """
            </div>"""

        # ì¶”ê°€ ì°¸ì¡° ì •ë³´ (ê´€ë ¨ ê¸°ì‚¬ + Google ê²€ìƒ‰ ì •ë³´ í†µí•©)
        all_references = []
        
        # ê´€ë ¨ ê¸°ì‚¬ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
        if "related_articles" in article_data and article_data["related_articles"]:
            for article in article_data["related_articles"][:10]:  # ìµœëŒ€ 10ê°œ
                title = article.get("title", "")
                link = article.get("link", article.get("url", ""))
                if title and link:
                    all_references.append({"title": title, "link": link})
        
        # Google ê²€ìƒ‰ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
        if "google_articles" in article_data and article_data["google_articles"]:
            for result in article_data["google_articles"][:5]:  # ìµœëŒ€ 5ê°œ
                title = result.get("title", "")
                link = result.get("link", result.get("url", ""))  # link ë˜ëŠ” url í‚¤ ì‚¬ìš©
                if title and link:
                    all_references.append({"title": title, "link": link})
        
        # ëª¨ë“  ì°¸ì¡° ì •ë³´ ì¶œë ¥
        if all_references:
            sources_html += """
            <h4 style="margin-top: 15px;">ğŸ” ì¶”ê°€ ì°¸ì¡° ì •ë³´</h4>
            <div class="source-list">"""
            
            for ref in all_references:
                display_title = ref["title"][:30] + "..." if len(ref["title"]) > 30 else ref["title"]
                sources_html += f'<a href="{ref["link"]}" target="_blank">{display_title}</a>'
                
            sources_html += """
            </div>"""

        if has_sources:
            sources_html += """
        </div>"""

        return sources_html

    def get_cached_topics(self) -> List[Dict]:
        """ìºì‹œëœ ì£¼ì œ ëª©ë¡ ë°˜í™˜"""
        return self.cache_manager.get_topic_summary()


def test_smart_generator():
    """ìŠ¤ë§ˆíŠ¸ ê¸°ì‚¬ ìƒì„± í…ŒìŠ¤íŠ¸"""

    generator = SmartArticleGenerator()

    # 1ìœ„ ë‰´ìŠ¤ì— ëŒ€í•œ ê¸°ì‚¬ ìƒì„±/ì—…ë°ì´íŠ¸
    result = generator.generate_or_update_article(rank=1)

    if result:
        print(f"\nê²°ê³¼: {result['status']}")
        print(f"ë©”ì‹œì§€: {result['message']}")
        print(f"ì£¼ì œ ID: {result.get('topic_id')}")
        print(f"ë²„ì „: {result.get('version')}")

        if result["status"] == "reused":
            print("â†’ ê¸°ì¡´ ê¸°ì‚¬ë¥¼ ì¬ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.")
        elif result["status"] == "updated":
            print("â†’ ìƒˆë¡œìš´ ì •ë³´ë¡œ ê¸°ì‚¬ë¥¼ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤.")
            print(f"   ì—…ë°ì´íŠ¸ ë‚´ìš©: {result.get('updates')}")
        elif result["status"] == "created":
            print("â†’ ì™„ì „íˆ ìƒˆë¡œìš´ ê¸°ì‚¬ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

    # ìºì‹œëœ ì£¼ì œ ëª©ë¡
    print("\n=== ìºì‹œëœ ì£¼ì œ ëª©ë¡ ===")
    topics = generator.get_cached_topics()
    for topic in topics[:5]:  # ìƒìœ„ 5ê°œë§Œ
        print(f"- {topic['title']} (v{topic['version']})")


def regenerate_html_for_cached_articles():
    """ìºì‹œëœ ê¸°ì‚¬ë“¤ì˜ HTMLì„ ì¬ìƒì„± (ë²„ì „ë³„ íŒŒì¼ í¬í•¨)"""

    generator = SmartArticleGenerator()
    cache_dir = "cache/articles"
    output_dir = "output/smart_articles"

    # ë²„ì „ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(f"{output_dir}/versions", exist_ok=True)

    # ìºì‹œ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  JSON íŒŒì¼ ì½ê¸°
    for filename in os.listdir(cache_dir):
        if filename.endswith(".json"):
            filepath = os.path.join(cache_dir, filename)

            # ìºì‹œ íŒŒì¼ ì½ê¸°
            with open(filepath, "r", encoding="utf-8") as f:
                article_data = json.load(f)

            # ë©”íƒ€ë°ì´í„° ì¶”ê°€ (analysis resultì—ì„œ ê°€ì ¸ì˜´)
            if "analysis" in article_data and isinstance(article_data["analysis"], dict):
                # YouTubeì™€ Google ì •ë³´ í™•ì¸
                if "youtube_context" in article_data["analysis"]:
                    article_data["youtube_videos"] = article_data["analysis"]["youtube_context"]
                if "google_context" in article_data["analysis"]:
                    article_data["google_articles"] = article_data["analysis"]["google_context"]

            # íŒŒì¼ëª… ìƒì„± (topic_id ê¸°ë°˜)
            topic_id = article_data.get("topic_id", filename.replace(".json", ""))
            version = article_data.get("version", 1)

            # ë²„ì „ íˆìŠ¤í† ë¦¬ í™•ì¸
            version_history = article_data.get("version_history", [])
            if version_history:
                # ëª¨ë“  ë²„ì „ì— ëŒ€í•´ HTML ìƒì„±
                for version_info in version_history:
                    if version_info.get("article_id") == topic_id:
                        # í˜„ì¬ ë²„ì „
                        html_output = generator._generate_html(
                            article_data,
                            article_data.get("related_articles_count", 1),
                            is_update=version > 1,
                        )

                        # ë²„ì „ë³„ íŒŒì¼ ì €ì¥
                        version_filename = f"article_{topic_id}_v{version}.html"
                        version_path = f"{output_dir}/versions/{version_filename}"

                        with open(version_path, "w", encoding="utf-8") as f:
                            f.write(html_output)

                        print(f"ë²„ì „ HTML ìƒì„±: {version_path}")
            else:
                # ë²„ì „ íˆìŠ¤í† ë¦¬ê°€ ì—†ëŠ” ê²½ìš° (êµ¬ ë²„ì „)
                html_output = generator._generate_html(
                    article_data,
                    article_data.get("related_articles_count", 1),
                    is_update=version > 1,
                )

                # í˜„ì¬ ë²„ì „ë§Œ ì €ì¥
                version_filename = f"article_{topic_id}_v{version}.html"
                version_path = f"{output_dir}/versions/{version_filename}"

                with open(version_path, "w", encoding="utf-8") as f:
                    f.write(html_output)

                print(f"ë²„ì „ HTML ìƒì„±: {version_path}")


def generate_top_articles(start_rank: int = 1, end_rank: int = 5):
    """1~5ìœ„ ê¸°ì‚¬ ì¼ê´„ ìƒì„± (ì¤‘ë³µ ë°©ì§€)"""

    generator = SmartArticleGenerator()
    results = generator.generate_multiple_articles(start_rank=start_rank, end_rank=end_rank)

    return results


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1:
        if sys.argv[1] == "--multiple" or sys.argv[1] == "all":
            # 1~5ìœ„ ì¼ê´„ ìƒì„±
            generate_top_articles(start_rank=1, end_rank=5)
        else:
            # ê°œë³„ ìˆœìœ„ ì§€ì • (ì˜ˆ: python smart_article_generator.py 1 3 5)
            try:
                ranks = [int(arg) for arg in sys.argv[1:]]
                generator = SmartArticleGenerator()
                
                logger.info(f"ì§€ì •ëœ ìˆœìœ„ ê¸°ì‚¬ ìƒì„±: {ranks}")
                
                for rank in ranks:
                    if 1 <= rank <= 10:  # 1~10ìœ„ë§Œ í—ˆìš©
                        logger.info(f"\n{'='*50}")
                        logger.info(f"{rank}ìœ„ ê¸°ì‚¬ ìƒì„± ì‹œì‘")
                        logger.info(f"{'='*50}")
                        
                        result = generator.generate_or_update_article(rank=rank)
                        
                        if result:
                            logger.info(f"{rank}ìœ„ ê¸°ì‚¬ ìƒì„± ì„±ê³µ")
                        else:
                            logger.error(f"{rank}ìœ„ ê¸°ì‚¬ ìƒì„± ì‹¤íŒ¨")
                    else:
                        logger.warning(f"ì˜ëª»ëœ ìˆœìœ„: {rank} (1~10 ì‚¬ì´ì—¬ì•¼ í•¨)")
                        
            except ValueError:
                logger.error("ì˜ëª»ëœ ì…ë ¥: ìˆœìœ„ëŠ” ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤")
                print("ì‚¬ìš©ë²•:")
                print("  python smart_article_generator.py         # 1ìœ„ ê¸°ì‚¬ë§Œ")
                print("  python smart_article_generator.py all  # 1~5ìœ„ ëª¨ë‘")
                print("  python smart_article_generator.py 1 3 5    # 1, 3, 5ìœ„ë§Œ")
    else:
        # ê¸°ë³¸: 1ìœ„ë§Œ ìƒì„± (ê¸°ì¡´ ë™ì‘)
        generate_top_articles(start_rank=1, end_rank=1)
