"""
Copyright (c) 2025 pjeehoon and KONA Project Contributors
This file is part of KONA (Korean Open News by AI).
Unauthorized commercial use is prohibited.
See LICENSE file for details.
"""

"""
ì‹¤ì‹œê°„ ì´ìŠˆ íŠ¸ë Œë“œ ë¶„ì„ ì‹œìŠ¤í…œ
ë„¤ì´ë²„ì˜ ì‹¤ì‹œê°„ ì¸ê¸° ë‰´ìŠ¤ì™€ ê²€ìƒ‰ íŠ¸ë Œë“œë¥¼ ë¶„ì„
"""

import json
import logging
import os
from datetime import datetime, timedelta
from typing import Dict, List, Tuple
import requests
from bs4 import BeautifulSoup
from collections import Counter
import re

logger = logging.getLogger(__name__)

class RealtimeTrendAnalyzer:
    """ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        self.output_dir = "news_data/trends"
        os.makedirs(self.output_dir, exist_ok=True)
        
        # ì˜ê²¬ ê¸°ì‚¬ í•„í„°ë§ íŒ¨í„´
        self.opinion_patterns = [
            '[ì‚¬ì„¤]', 'ã€ì‚¬ì„¤ã€‘', 'ï¼œì‚¬ì„¤ï¼', '<ì‚¬ì„¤>', '(ì‚¬ì„¤)',
            '[ì¹¼ëŸ¼]', 'ã€ì¹¼ëŸ¼ã€‘', 'ï¼œì¹¼ëŸ¼ï¼', '<ì¹¼ëŸ¼>', '(ì¹¼ëŸ¼)',
            '[ê¸°ê³ ]', 'ã€ê¸°ê³ ã€‘', 'ï¼œê¸°ê³ ï¼', '<ê¸°ê³ >', '(ê¸°ê³ )',
            '[íŠ¹ë³„ê¸°ê³ ]', '[ì‹œë¡ ]', '[ë…¼ë‹¨]', '[ê¸°ììˆ˜ì²©]', '[ë°ìŠ¤í¬ì¹¼ëŸ¼]',
            '[í¸ì§‘êµ­ì—ì„œ]', '[ì—¬ì ]', '[ë§Œë¬¼ìƒ]', '[ì²œìì¹¼ëŸ¼]', '[ì¶˜ì¶”ì¹¼ëŸ¼]',
            '[ì„¸ìƒì½ê¸°]', '[ì‹œí‰]', '[ë…ìíˆ¬ê³ ]', '[ë…ìê¸°ê³ ]', '[ì˜¤í”¼ë‹ˆì–¸]',
            '[ì‚¬ë‚´ì¹¼ëŸ¼]', '[ì·¨ì¬ìˆ˜ì²©]', '[ê¸°ìì¹¼ëŸ¼]', '[ì•„ì¹¨ë…¼ë‹¨]', '[ê´‘í™”ë¬¸ì—ì„œ]',
            '[ì—¬ì˜ë„í¬ëŸ¼]', '[ë¶„ìˆ˜ëŒ€]', '[ë…¹ì·¨ë¡]', '[ì¸í„°ë·°]', '[ëŒ€ë‹´]'
        ]
    
    def get_naver_hot_news(self) -> List[Dict]:
        """ë„¤ì´ë²„ ë©”ì¸ì˜ ë§ì´ ë³¸ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        logger.info("ë„¤ì´ë²„ ë§ì´ ë³¸ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")
        
        try:
            # ë„¤ì´ë²„ ë‰´ìŠ¤ í™ˆì—ì„œ ë§ì´ ë³¸ ë‰´ìŠ¤ ìˆ˜ì§‘
            url = "https://news.naver.com/main/ranking/popularDay.naver"
            logger.info(f"ë„¤ì´ë²„ ë‰´ìŠ¤ ìš”ì²­ ì¤‘: {url}")
            response = requests.get(url, headers=self.headers)
            logger.info(f"ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}, í¬ê¸°: {len(response.text)} bytes")
            soup = BeautifulSoup(response.text, 'html.parser')
            
            hot_news = []
            
            # ë­í‚¹ ë°•ìŠ¤ ì°¾ê¸°
            ranking_boxes = soup.find_all('div', class_='rankingnews_box')
            
            # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘ (ë‹¤ì–‘ì„± í™•ë³´)
            category_names = ['ì¢…í•©', 'ì •ì¹˜', 'ê²½ì œ', 'ì‚¬íšŒ', 'ìƒí™œ/ë¬¸í™”', 'ì„¸ê³„', 'IT/ê³¼í•™']
            news_per_category = 10  # ê° ì¹´í…Œê³ ë¦¬ì—ì„œ 10ê°œì”©
            
            for box_idx, box in enumerate(ranking_boxes[:6]):  # ìµœëŒ€ 6ê°œ ì¹´í…Œê³ ë¦¬
                # ì¹´í…Œê³ ë¦¬ ì´ë¦„ ì¶”ì¶œ ì‹œë„
                category_header = box.find_previous_sibling(['h4', 'h5']) or box.find_parent().find(['h4', 'h5'])
                if category_header:
                    category_name = category_header.get_text(strip=True)
                else:
                    category_name = category_names[box_idx] if box_idx < len(category_names) else f"ì¹´í…Œê³ ë¦¬{box_idx+1}"
                
                news_items = box.find_all('li')
                
                # ê° ì¹´í…Œê³ ë¦¬ì—ì„œ ìƒìœ„ ë‰´ìŠ¤ ìˆ˜ì§‘
                for item_idx, item in enumerate(news_items[:news_per_category]):
                    link_tag = item.find('a')
                    if link_tag:
                        title = link_tag.get_text(strip=True)
                        link = link_tag.get('href', '')
                        if not link.startswith('http'):
                            link = 'https://news.naver.com' + link
                        
                        # ì‚¬ì„¤, ì¹¼ëŸ¼, ê¸°ê³  ë“± ì˜ê²¬ ê¸°ì‚¬ í•„í„°ë§
                        if self._is_opinion_article(title):
                            logger.info(f"ì˜ê²¬ ê¸°ì‚¬ ì œì™¸: {title[:30]}...")
                            continue
                        
                        hot_news.append({
                            'rank': len(hot_news) + 1,
                            'title': title,
                            'link': link,
                            'source': 'naver_ranking',
                            'category': category_name,
                            'collected_at': datetime.now().isoformat()
                        })
            
            # ëª» ì°¾ì€ ê²½ìš° ë‹¤ë¥¸ ì„ íƒì ì‹œë„
            if not hot_news:
                # ëŒ€ì²´ ì„ íƒì ì‹œë„
                news_list = soup.find('ol', class_='rankingnews_list')
                if news_list:
                    items = news_list.find_all('li')
                    for idx, item in enumerate(items[:10], 1):
                        link_tag = item.find('a')
                        if link_tag:
                            title = link_tag.get_text(strip=True)
                            link = link_tag.get('href', '')
                            
                            # ì‚¬ì„¤, ì¹¼ëŸ¼, ê¸°ê³  ë“± ì˜ê²¬ ê¸°ì‚¬ í•„í„°ë§
                            if self._is_opinion_article(title):
                                logger.info(f"ì˜ê²¬ ê¸°ì‚¬ ì œì™¸: {title[:30]}...")
                                continue
                            
                            hot_news.append({
                                'rank': idx,
                                'title': title,
                                'link': link,
                                'source': 'naver_ranking',
                                'collected_at': datetime.now().isoformat()
                            })
            
            logger.info(f"ë§ì´ ë³¸ ë‰´ìŠ¤ {len(hot_news)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
            return hot_news
            
        except Exception as e:
            logger.error(f"ë„¤ì´ë²„ í•« ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []
    
    def get_trending_keywords(self, news_list: List[Dict]) -> List[Tuple[str, int]]:
        """ë‰´ìŠ¤ ì œëª©ì—ì„œ íŠ¸ë Œë”© í‚¤ì›Œë“œ ì¶”ì¶œ"""
        logger.info("íŠ¸ë Œë”© í‚¤ì›Œë“œ ë¶„ì„ ì‹œì‘")
        
        # ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸
        stopwords = {'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì˜', 'ì—', 'ì™€', 'ê³¼', 'ë„', 
                    'ë¡œ', 'ìœ¼ë¡œ', 'ë§Œ', 'ì—ì„œ', 'ê¹Œì§€', 'ë¶€í„°', 'í–ˆë‹¤', 'í•œë‹¤', 'í•˜ëŠ”',
                    'ìœ„í•´', 'ë”°ë¼', 'ë°', 'ë“±', 'ê²ƒ', 'ìˆ˜', 'ì¤‘', 'í• ', 'ëœ', 'ëŒ€í•´'}
        
        # ëª¨ë“  ì œëª©ì—ì„œ ëª…ì‚¬ ì¶”ì¶œ
        all_words = []
        for news in news_list:
            title = news.get('title', '')
            # í•œê¸€, ì˜ì–´, ìˆ«ìë§Œ ì¶”ì¶œ
            words = re.findall(r'[ê°€-í£]+|[a-zA-Z]+|[0-9]+', title)
            # 2ê¸€ì ì´ìƒë§Œ í•„í„°ë§
            words = [w for w in words if len(w) >= 2 and w not in stopwords]
            all_words.extend(words)
        
        # ë¹ˆë„ìˆ˜ ê³„ì‚°
        word_counter = Counter(all_words)
        trending_keywords = word_counter.most_common(20)
        
        logger.info(f"íŠ¸ë Œë”© í‚¤ì›Œë“œ {len(trending_keywords)}ê°œ ì¶”ì¶œ ì™„ë£Œ")
        return trending_keywords
    
    def analyze_trend_categories(self, news_list: List[Dict]) -> Dict[str, int]:
        """íŠ¸ë Œë“œ ì¹´í…Œê³ ë¦¬ ë¶„ì„"""
        # ìˆ˜ì§‘ëœ ë‰´ìŠ¤ì˜ ì‹¤ì œ ì¹´í…Œê³ ë¦¬ ì •ë³´ ì‚¬ìš©
        category_count = {}
        
        for news in news_list:
            # ë‰´ìŠ¤ì— ì¹´í…Œê³ ë¦¬ ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            if 'category' in news:
                category = news['category']
                if category not in category_count:
                    category_count[category] = 0
                category_count[category] += 1
            else:
                # ì¹´í…Œê³ ë¦¬ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì œëª© ê¸°ë°˜ ë¶„ì„ (ì´ì „ ë°©ì‹)
                title = news.get('title', '')
                categories = {
                    'ì •ì¹˜': ['ëŒ€í†µë ¹', 'êµ­íšŒ', 'ì •ë‹¹', 'ì„ ê±°', 'ì˜ì›', 'ì •ë¶€', 'ì²­ì™€ëŒ€', 'ì´ë¦¬'],
                    'ê²½ì œ': ['ì£¼ì‹', 'ë¶€ë™ì‚°', 'ê¸ˆë¦¬', 'í™˜ìœ¨', 'íˆ¬ì', 'ì‹œì¥', 'ê²½ì œ', 'ê¸°ì—…'],
                    'ì‚¬íšŒ': ['ì‚¬ê±´', 'ì‚¬ê³ ', 'ë²”ì£„', 'ì¬íŒ', 'ê²½ì°°', 'ê²€ì°°', 'ë²•ì›', 'ì‹œë¯¼'],
                    'ì—°ì˜ˆ': ['ë°°ìš°', 'ê°€ìˆ˜', 'ì•„ì´ëŒ', 'ë“œë¼ë§ˆ', 'ì˜í™”', 'ë°©ì†¡', 'ì—°ì˜ˆì¸', 'TV'],
                    'ìŠ¤í¬ì¸ ': ['ì¶•êµ¬', 'ì•¼êµ¬', 'ë†êµ¬', 'ê³¨í”„', 'ì„ ìˆ˜', 'ê°ë…', 'ê²½ê¸°', 'ë¦¬ê·¸'],
                    'êµ­ì œ': ['ë¯¸êµ­', 'ì¤‘êµ­', 'ì¼ë³¸', 'ëŸ¬ì‹œì•„', 'ë¶í•œ', 'ìœ ëŸ½', 'ì™¸êµ', 'êµ­ì œ'],
                    'IT/ê³¼í•™': ['AI', 'ì¸ê³µì§€ëŠ¥', 'ìŠ¤ë§ˆíŠ¸í°', 'ì•±', 'ê²Œì„', 'ì¸í„°ë„·', 'SNS', 'ê¸°ìˆ ', 'ê³¼í•™']
                }
                
                for category, keywords in categories.items():
                    if any(keyword in title for keyword in keywords):
                        if category not in category_count:
                            category_count[category] = 0
                        category_count[category] += 1
                        break  # í•œ ì¹´í…Œê³ ë¦¬ì—ë§Œ ë¶„ë¥˜
        
        return category_count
    
    def get_time_based_trends(self) -> Dict:
        """ì‹œê°„ëŒ€ë³„ íŠ¸ë Œë“œ ë¶„ì„"""
        current_hour = datetime.now().hour
        
        # ì‹œê°„ëŒ€ë³„ íŠ¹ì„±
        time_characteristics = {
            'morning': (6, 9, "ì¶œê·¼ê¸¸ ì£¼ìš” ì´ìŠˆ"),
            'late_morning': (9, 12, "ì˜¤ì „ ì£¼ìš” ë‰´ìŠ¤"),
            'lunch': (12, 14, "ì ì‹¬ì‹œê°„ í™”ì œ"),
            'afternoon': (14, 18, "ì˜¤í›„ ì£¼ìš” ì´ìŠˆ"),
            'evening': (18, 21, "ì €ë… ì£¼ìš” ë‰´ìŠ¤"),
            'night': (21, 24, "ë°¤ ì‹œê°„ ì´ìŠˆ"),
            'dawn': (0, 6, "ìƒˆë²½ ì†ë³´")
        }
        
        for period, (start, end, description) in time_characteristics.items():
            if start <= current_hour < end or (period == 'dawn' and (current_hour >= 0 or current_hour < 6)):
                return {
                    'period': period,
                    'description': description,
                    'current_hour': current_hour
                }
        
        return {'period': 'unknown', 'description': 'ì‹œê°„ëŒ€ ë¶„ì„ ë¶ˆê°€', 'current_hour': current_hour}
    
    def detect_emerging_issues(self, current_trends: List[Dict], 
                              previous_trends: List[Dict] = None) -> List[Dict]:
        """ê¸‰ìƒìŠ¹ ì´ìŠˆ ê°ì§€"""
        if not previous_trends:
            return []
        
        emerging = []
        
        # ì´ì „ íŠ¸ë Œë“œë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        prev_dict = {item['title']: item['rank'] for item in previous_trends}
        
        for current in current_trends:
            title = current['title']
            current_rank = current['rank']
            
            # ìƒˆë¡œ ë“±ì¥í–ˆê±°ë‚˜ ìˆœìœ„ê°€ í¬ê²Œ ìƒìŠ¹í•œ ê²½ìš°
            if title not in prev_dict:
                emerging.append({
                    'title': title,
                    'type': 'new',
                    'current_rank': current_rank,
                    'change': 'NEW'
                })
            elif prev_dict[title] - current_rank >= 3:  # 3ìˆœìœ„ ì´ìƒ ìƒìŠ¹
                emerging.append({
                    'title': title,
                    'type': 'rising',
                    'current_rank': current_rank,
                    'previous_rank': prev_dict[title],
                    'change': prev_dict[title] - current_rank
                })
        
        return emerging
    
    def analyze_realtime_trends(self) -> Dict:
        """ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ì¢…í•© ë¶„ì„"""
        logger.info("=== ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë¶„ì„ ì‹œì‘ ===")
        
        # 1. ë„¤ì´ë²„ í•« ë‰´ìŠ¤ ìˆ˜ì§‘
        hot_news = self.get_naver_hot_news()
        
        # 2. íŠ¸ë Œë”© í‚¤ì›Œë“œ ì¶”ì¶œ
        trending_keywords = self.get_trending_keywords(hot_news)
        
        # 3. ì¹´í…Œê³ ë¦¬ ë¶„ì„
        category_analysis = self.analyze_trend_categories(hot_news)
        
        # 4. ì‹œê°„ëŒ€ ë¶„ì„
        time_analysis = self.get_time_based_trends()
        
        # 5. ì´ì „ íŠ¸ë Œë“œì™€ ë¹„êµ (ìˆë‹¤ë©´)
        previous_file = self.get_latest_trend_file()
        emerging_issues = []
        
        if previous_file:
            with open(previous_file, 'r', encoding='utf-8') as f:
                previous_data = json.load(f)
                previous_trends = previous_data.get('hot_news', [])
                emerging_issues = self.detect_emerging_issues(hot_news, previous_trends)
        
        # ê²°ê³¼ ì¢…í•©
        result = {
            'timestamp': datetime.now().isoformat(),
            'time_analysis': time_analysis,
            'hot_news': hot_news,
            'trending_keywords': trending_keywords,
            'category_distribution': category_analysis,
            'emerging_issues': emerging_issues,
            'summary': self.create_trend_summary(hot_news, trending_keywords, emerging_issues)
        }
        
        # ê²°ê³¼ ì €ì¥
        self.save_trend_data(result)
        
        logger.info("=== ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë¶„ì„ ì™„ë£Œ ===")
        return result
    
    def create_trend_summary(self, hot_news: List[Dict], 
                           keywords: List[Tuple[str, int]], 
                           emerging: List[Dict]) -> Dict:
        """íŠ¸ë Œë“œ ìš”ì•½ ìƒì„±"""
        summary = {
            'total_trending_news': len(hot_news),
            'top_keywords': [kw[0] for kw in keywords[:5]],
            'emerging_count': len(emerging),
            'analysis_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # ê°€ì¥ í•«í•œ ì´ìŠˆ 3ê°œ
        if hot_news:
            summary['top_issues'] = [news['title'] for news in hot_news[:3]]
        
        # ê¸‰ìƒìŠ¹ ì´ìŠˆ
        if emerging:
            summary['emerging_titles'] = [e['title'] for e in emerging[:3]]
        
        return summary
    
    def get_latest_trend_file(self) -> str:
        """ê°€ì¥ ìµœê·¼ íŠ¸ë Œë“œ íŒŒì¼ ì°¾ê¸°"""
        files = [f for f in os.listdir(self.output_dir) if f.startswith('trend_')]
        if not files:
            return None
        
        files.sort(reverse=True)
        return os.path.join(self.output_dir, files[0])
    
    def save_trend_data(self, data: Dict):
        """íŠ¸ë Œë“œ ë°ì´í„° ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{self.output_dir}/trend_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"íŠ¸ë Œë“œ ë°ì´í„° ì €ì¥: {filename}")
        
        # HTML ë¦¬í¬íŠ¸ë„ ìƒì„±
        self.generate_html_report(data, timestamp)
    
    def _format_emerging_issue(self, issue: Dict) -> str:
        """ê¸‰ìƒìŠ¹ ì´ìŠˆ í¬ë§·íŒ…"""
        badge = '<span class="new-badge">NEW</span>' if issue.get('type') == 'new' else f'â†‘{issue.get("change", "")}'
        return f'''
        <div class="emerging">
            {badge}
            {issue.get('title', '')}
        </div>
        '''
    
    def generate_html_report(self, data: Dict, timestamp: str):
        """HTML í˜•ì‹ì˜ íŠ¸ë Œë“œ ë¦¬í¬íŠ¸ ìƒì„±"""
        html_content = f"""
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë¶„ì„ - {timestamp}</title>
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: #f5f5f5;
        }}
        .header {{
            background: white;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        .section {{
            background: white;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        .trend-item {{
            padding: 10px;
            border-bottom: 1px solid #eee;
        }}
        .trend-item:last-child {{
            border-bottom: none;
        }}
        .rank {{
            display: inline-block;
            width: 30px;
            height: 30px;
            background: #007bff;
            color: white;
            text-align: center;
            line-height: 30px;
            border-radius: 50%;
            margin-right: 10px;
        }}
        .keyword {{
            display: inline-block;
            padding: 5px 10px;
            background: #e9ecef;
            border-radius: 20px;
            margin: 5px;
        }}
        .emerging {{
            background: #fff3cd;
            padding: 10px;
            border-radius: 5px;
            margin: 5px 0;
        }}
        .new-badge {{
            background: #dc3545;
            color: white;
            padding: 2px 8px;
            border-radius: 10px;
            font-size: 12px;
        }}
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ”¥ ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë¶„ì„</h1>
        <p>ë¶„ì„ ì‹œê°„: {data['summary']['analysis_time']}</p>
        <p>{data['time_analysis']['description']} ({data['time_analysis']['current_hour']}ì‹œ)</p>
    </div>
    
    <div class="section">
        <h2>ğŸ“Š íŠ¸ë Œë“œ ìš”ì•½</h2>
        <p>ì´ {data['summary']['total_trending_news']}ê°œì˜ í•« ì´ìŠˆ ê°ì§€</p>
        <p>ê¸‰ìƒìŠ¹ ì´ìŠˆ: {data['summary']['emerging_count']}ê°œ</p>
        <div>
            <strong>TOP í‚¤ì›Œë“œ:</strong>
            {' '.join(f'<span class="keyword">{kw}</span>' for kw in data['summary']['top_keywords'])}
        </div>
    </div>
    
    <div class="section">
        <h2>ğŸ† ì‹¤ì‹œê°„ ì¸ê¸° ë‰´ìŠ¤</h2>
        {''.join(f'''
        <div class="trend-item">
            <span class="rank">{news["rank"]}</span>
            <a href="{news["link"]}" target="_blank">{news["title"]}</a>
        </div>
        ''' for news in data['hot_news'])}
    </div>
    
    <div class="section">
        <h2>ğŸš€ ê¸‰ìƒìŠ¹ ì´ìŠˆ</h2>
        {''.join(self._format_emerging_issue(issue) for issue in data.get('emerging_issues', []))}
    </div>
    
    <div class="section">
        <h2>ğŸ·ï¸ íŠ¸ë Œë”© í‚¤ì›Œë“œ</h2>
        <div>
            {' '.join(f'<span class="keyword">{kw[0]} ({kw[1]})</span>' 
                     for kw in data['trending_keywords'][:15])}
        </div>
    </div>
</body>
</html>
"""
        
        html_path = f"output/trends/trend_report_{timestamp}.html"
        os.makedirs("output/trends", exist_ok=True)
        
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        logger.info(f"HTML ë¦¬í¬íŠ¸ ìƒì„±: {html_path}")
    
    def _is_opinion_article(self, title: str) -> bool:
        """ì œëª©ì„ ê¸°ë°˜ìœ¼ë¡œ ì˜ê²¬ ê¸°ì‚¬(ì‚¬ì„¤, ì¹¼ëŸ¼ ë“±) íŒë³„"""
        # ëª¨ë“  ì¢…ë¥˜ì˜ ê´„í˜¸ ([], (), {}, <>, ã€ã€‘, ï¼œï¼, ï¼ˆï¼‰, ï½›ï½) í˜•ì‹ì´ ìˆëŠ” ê¸°ì‚¬ í•„í„°ë§
        import re
        if re.search(r'[\[\(\{<ã€ï¼œï¼ˆï½›].+?[\]\)\}>ã€‘ï¼ï¼‰ï½]', title):
            return True
        
        # ì œëª©ì— ì˜ê²¬ ê¸°ì‚¬ íŒ¨í„´ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        for pattern in self.opinion_patterns:
            if pattern in title:
                return True
        
        # ì¶”ê°€ íŒ¨í„´: ì œëª© ì‹œì‘ ë¶€ë¶„ì— ìˆëŠ” ê²½ìš°
        title_start = title[:20]  # ì œëª© ì•ë¶€ë¶„ë§Œ í™•ì¸
        opinion_keywords = ['ì‚¬ì„¤', 'ì¹¼ëŸ¼', 'ê¸°ê³ ', 'ì‹œë¡ ', 'ë…¼ë‹¨', 'ì‹œí‰', 'ê¸°ììˆ˜ì²©']
        for keyword in opinion_keywords:
            if keyword in title_start and (title_start.index(keyword) < 10):
                return True
        
        return False


# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    analyzer = RealtimeTrendAnalyzer()
    result = analyzer.analyze_realtime_trends()
    
    print("\n=== ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼ ===")
    print(f"ë¶„ì„ ì‹œê°„: {result['summary']['analysis_time']}")
    print(f"ì‹œê°„ëŒ€: {result['time_analysis']['description']}")
    print(f"\nğŸ”¥ TOP 3 ì´ìŠˆ:")
    for i, issue in enumerate(result['summary'].get('top_issues', []), 1):
        print(f"{i}. {issue}")
    
    print(f"\nğŸ“ˆ íŠ¸ë Œë”© í‚¤ì›Œë“œ:")
    for keyword, count in result['trending_keywords'][:5]:
        print(f"- {keyword} ({count}íšŒ)")