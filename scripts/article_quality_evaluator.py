"""
Copyright (c) 2025 pjeehoon and KONA Project Contributors
This file is part of KONA (Korean Open News by AI).
Unauthorized commercial use is prohibited.
See LICENSE file for details.
"""

"""
ê¸°ì‚¬ í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ
betterNews ìŠ¤íƒ€ì¼ì˜ í’ˆì§ˆ í‰ê°€ ê¸°ì¤€ì„ ì ìš©í•˜ì—¬
ìƒì„±ëœ ê¸°ì‚¬ì˜ í’ˆì§ˆì„ High/Medium/Lowë¡œ í‰ê°€
"""

import logging
import re
from typing import Dict, List, Tuple
from datetime import datetime

logger = logging.getLogger(__name__)


class ArticleQualityEvaluator:
    """ê¸°ì‚¬ í’ˆì§ˆ í‰ê°€ê¸°"""
    
    def __init__(self):
        # í‰ê°€ ê¸°ì¤€ ì •ì˜
        self.quality_criteria = {
            "High": {
                "description": "ë‹¨ìˆœí•œ ì •ë³´ ì „ë‹¬ ë¿ë§Œ ì•„ë‹ˆë¼, í•´ë‹¹ ì •ë³´ì— ëŒ€í•œ í‰ê°€ë¥¼ ì œê³µí•˜ë©°, ê·¸ í‰ê°€ê°€ ë„ì¶œëœ ê·¼ê±°ë¥¼ ì œì‹œ",
                "emoji": "ğŸ˜Š",
                "min_score": 0.7
            },
            "Medium": {
                "description": "ë‹¨ìˆœí•œ ì •ë³´ë¥¼ ì „ë‹¬í•œ ë¿, í•´ë‹¹ ì •ë³´ì— ëŒ€í•œ í‰ê°€ê°€ ì—†ê±°ë‚˜, í‰ê°€ê°€ ìˆì–´ë„ ê·¸ í‰ê°€ê°€ ë„ì¶œëœ ê·¼ê±°ê°€ ë¶€ì¡±",
                "emoji": "ğŸ˜",
                "min_score": 0.4
            },
            "Low": {
                "description": "ì •ë³´ ì „ë‹¬ì— ìˆì–´ì„œë„ ì¶œì²˜ê°€ ë¶ˆëª…í™•í•˜ì—¬ í•´ë‹¹ ì •ë³´ì˜ ì‚¬ì‹¤ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê¸° ì–´ë µê±°ë‚˜, í•´ë‹¹ ì •ë³´ë¥¼ ì˜ëª»ëœ ë°©ë²•ìœ¼ë¡œ í•´ì„",
                "emoji": "â˜¹ï¸",
                "min_score": 0.0
            }
        }
        
        # ëª¨í˜¸í•œ ì¶œì²˜ í‘œí˜„ íŒ¨í„´
        self.vague_source_patterns = [
            r"í•œ\s*ê´€ê³„ì",
            r"ì •í†µí•œ\s*ì†Œì‹í†µ",
            r"ìµëª…ì˜?\s*ê´€ê³„ì",
            r"ì†Œì‹í†µ",
            r"ê´€ê³„ì",
            r"ì•Œë ¤ì§„\s*ë°”ì—?\s*ë”°ë¥´ë©´",
            r"ì „í•´ì§„ë‹¤",
            r"ì•Œë ¤ì¡Œë‹¤",
            r"~ê²ƒìœ¼ë¡œ\s*ë³´ì¸ë‹¤",
            r"~ê²ƒìœ¼ë¡œ\s*ì¶”ì •ëœë‹¤"
        ]
        
        # êµ¬ì²´ì  ì¶œì²˜ í‘œí˜„ íŒ¨í„´
        self.specific_source_patterns = [
            r"\[.+\]\(.+\)",  # ë§ˆí¬ë‹¤ìš´ ë§í¬
            r"ì—\s*ë”°ë¥´ë©´",
            r"ë°œí‘œ",
            r"ë³´ë„",
            r"ë°í˜”ë‹¤",
            r"ì „í–ˆë‹¤",
            r"\d{4}ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼",  # êµ¬ì²´ì  ë‚ ì§œ
            r"ê³µì‹",
            r"ì„±ëª…",
            r"ì¸í„°ë·°"
        ]
    
    def evaluate_article(self, article: Dict[str, any]) -> Tuple[str, str, Dict]:
        """
        ê¸°ì‚¬ í’ˆì§ˆ í‰ê°€
        
        Args:
            article: í‰ê°€í•  ê¸°ì‚¬ ë°ì´í„°
            
        Returns:
            (í’ˆì§ˆ ë“±ê¸‰, ì´ëª¨ì§€, ìƒì„¸ í‰ê°€ ê²°ê³¼)
        """
        scores = {
            "evidence_quality": self._check_evidence_quality(article),
            "source_transparency": self._check_source_transparency(article),
            "balance_and_objectivity": self._check_balance(article),
            "fact_verification": self._check_fact_verification(article),
            "analysis_depth": self._check_analysis_depth(article)
        }
        
        # ì „ì²´ ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘í‰ê· )
        weights = {
            "evidence_quality": 0.25,
            "source_transparency": 0.25,
            "balance_and_objectivity": 0.20,
            "fact_verification": 0.20,
            "analysis_depth": 0.10
        }
        
        total_score = sum(scores[key] * weights[key] for key in scores)
        
        # í’ˆì§ˆ ë“±ê¸‰ ê²°ì •
        quality_rating = self._determine_quality_rating(total_score)
        emoji = self.quality_criteria[quality_rating]["emoji"]
        
        # ìƒì„¸ í‰ê°€ ê²°ê³¼
        evaluation_details = {
            "quality_rating": quality_rating,
            "emoji": emoji,
            "total_score": round(total_score, 2),
            "scores": scores,
            "strengths": self._identify_strengths(scores),
            "weaknesses": self._identify_weaknesses(scores),
            "recommendations": self._generate_recommendations(scores)
        }
        
        return quality_rating, emoji, evaluation_details
    
    def _check_evidence_quality(self, article: Dict) -> float:
        """ì¦ê±° í’ˆì§ˆ í‰ê°€"""
        content = article.get("comprehensive_article", article.get("generated_article", ""))
        if not content:
            return 0.0
        
        score = 0.0
        
        # êµ¬ì²´ì  ì¦ê±° í™•ì¸
        evidence_indicators = [
            (r"\d+[%ï¼…]", 0.1),  # ë°±ë¶„ìœ¨
            (r"\d+[ëª…ì–µë§Œì²œ]", 0.1),  # ìˆ˜ì¹˜
            (r"ì¡°ì‚¬\s*ê²°ê³¼", 0.15),  # ì¡°ì‚¬ ê²°ê³¼
            (r"ë³´ê³ ì„œ", 0.15),  # ë³´ê³ ì„œ
            (r"í†µê³„", 0.1),  # í†µê³„
            (r"ì—°êµ¬", 0.1),  # ì—°êµ¬
            (r"ë°œí‘œ", 0.1),  # ë°œí‘œ
            (r"ê³µì‹", 0.1),  # ê³µì‹
            (r"ë¬¸ì„œ", 0.1),  # ë¬¸ì„œ
        ]
        
        for pattern, weight in evidence_indicators:
            if re.search(pattern, content):
                score += weight
        
        return min(score, 1.0)
    
    def _check_source_transparency(self, article: Dict) -> float:
        """ì¶œì²˜ íˆ¬ëª…ì„± í‰ê°€"""
        content = article.get("comprehensive_article", article.get("generated_article", ""))
        if not content:
            return 0.0
        
        # ëª¨í˜¸í•œ ì¶œì²˜ ì¹´ìš´íŠ¸
        vague_count = sum(1 for pattern in self.vague_source_patterns 
                         if re.search(pattern, content))
        
        # êµ¬ì²´ì  ì¶œì²˜ ì¹´ìš´íŠ¸
        specific_count = sum(1 for pattern in self.specific_source_patterns 
                           if re.search(pattern, content))
        
        # ë§ˆí¬ë‹¤ìš´ ë§í¬ ê°œìˆ˜
        link_count = len(re.findall(r"\[.+?\]\(.+?\)", content))
        
        # ì ìˆ˜ ê³„ì‚°
        if specific_count + link_count == 0:
            return 0.0
        
        transparency_ratio = (specific_count + link_count * 2) / (specific_count + link_count + vague_count)
        return min(transparency_ratio, 1.0)
    
    def _check_balance(self, article: Dict) -> float:
        """ê· í˜•ì„±ê³¼ ê°ê´€ì„± í‰ê°€"""
        content = article.get("comprehensive_article", article.get("generated_article", ""))
        if not content:
            return 0.0
        
        score = 0.0
        
        # ë‹¤ì–‘í•œ ê´€ì  í‘œí˜„ í™•ì¸
        balance_indicators = [
            (r"í•œí¸", 0.15),
            (r"ë°˜ë©´", 0.15),
            (r"ê·¸ëŸ¬ë‚˜", 0.1),
            (r"ë‹¤ë§Œ", 0.1),
            (r"ì°¬ì„±", 0.1),
            (r"ë°˜ëŒ€", 0.1),
            (r"ê¸ì •", 0.1),
            (r"ë¶€ì •", 0.1),
            (r"ì „ë¬¸ê°€", 0.1),
        ]
        
        for pattern, weight in balance_indicators:
            if re.search(pattern, content):
                score += weight
        
        return min(score, 1.0)
    
    def _check_fact_verification(self, article: Dict) -> float:
        """ì‚¬ì‹¤ ê²€ì¦ ê°€ëŠ¥ì„± í‰ê°€"""
        content = article.get("comprehensive_article", article.get("generated_article", ""))
        if not content:
            return 0.0
        
        score = 0.0
        
        # ê²€ì¦ ê°€ëŠ¥í•œ ì‚¬ì‹¤ í‘œí˜„
        verification_indicators = [
            (r"í™•ì¸ëë‹¤", 0.2),
            (r"ê²€ì¦", 0.2),
            (r"ì‚¬ì‹¤", 0.1),
            (r"ê³µì‹\s*í™•ì¸", 0.2),
            (r"ì¦ëª…", 0.1),
            (r"ì…ì¦", 0.1),
            (r"ë°í˜€ì¡Œë‹¤", 0.1),
        ]
        
        for pattern, weight in verification_indicators:
            if re.search(pattern, content):
                score += weight
        
        # ë§í¬ê°€ ìˆìœ¼ë©´ ì¶”ê°€ ì ìˆ˜
        link_count = len(re.findall(r"\[.+?\]\(.+?\)", content))
        score += min(link_count * 0.05, 0.3)
        
        return min(score, 1.0)
    
    def _check_analysis_depth(self, article: Dict) -> float:
        """ë¶„ì„ ê¹Šì´ í‰ê°€"""
        content = article.get("comprehensive_article", article.get("generated_article", ""))
        if not content:
            return 0.0
        
        # ê¸°ì‚¬ ê¸¸ì´ (ë¶„ì„ ê¹Šì´ì˜ ê¸°ë³¸ ì§€í‘œ)
        word_count = len(content.split())
        length_score = min(word_count / 1000, 0.5)  # 1000ë‹¨ì–´ ê¸°ì¤€
        
        # ë¶„ì„ì  í‘œí˜„
        analysis_indicators = [
            (r"ë¶„ì„", 0.1),
            (r"í‰ê°€", 0.1),
            (r"ì˜ë¯¸", 0.1),
            (r"ì˜í–¥", 0.1),
            (r"ì „ë§", 0.1),
            (r"ì‹œì‚¬ì ", 0.1),
            (r"ë°°ê²½", 0.1),
            (r"ì›ì¸", 0.1),
            (r"ê²°ê³¼", 0.1),
        ]
        
        analysis_score = 0.0
        for pattern, weight in analysis_indicators:
            if re.search(pattern, content):
                analysis_score += weight
        
        return min(length_score + analysis_score * 0.5, 1.0)
    
    def _determine_quality_rating(self, score: float) -> str:
        """ì ìˆ˜ì— ë”°ë¥¸ í’ˆì§ˆ ë“±ê¸‰ ê²°ì •"""
        if score >= self.quality_criteria["High"]["min_score"]:
            return "High"
        elif score >= self.quality_criteria["Medium"]["min_score"]:
            return "Medium"
        else:
            return "Low"
    
    def _identify_strengths(self, scores: Dict[str, float]) -> List[str]:
        """ê°•ì  ì‹ë³„"""
        strengths = []
        
        if scores["evidence_quality"] >= 0.7:
            strengths.append("êµ¬ì²´ì ì¸ ì¦ê±°ì™€ ìˆ˜ì¹˜ ì œì‹œ")
        if scores["source_transparency"] >= 0.7:
            strengths.append("ëª…í™•í•œ ì¶œì²˜ í‘œì‹œ")
        if scores["balance_and_objectivity"] >= 0.7:
            strengths.append("ê· í˜•ì¡íŒ ê´€ì  ì œì‹œ")
        if scores["fact_verification"] >= 0.7:
            strengths.append("ê²€ì¦ ê°€ëŠ¥í•œ ì‚¬ì‹¤ ìœ„ì£¼")
        if scores["analysis_depth"] >= 0.7:
            strengths.append("ì‹¬ì¸µì ì¸ ë¶„ì„ í¬í•¨")
        
        return strengths
    
    def _identify_weaknesses(self, scores: Dict[str, float]) -> List[str]:
        """ì•½ì  ì‹ë³„"""
        weaknesses = []
        
        if scores["evidence_quality"] < 0.4:
            weaknesses.append("êµ¬ì²´ì  ì¦ê±° ë¶€ì¡±")
        if scores["source_transparency"] < 0.4:
            weaknesses.append("ëª¨í˜¸í•œ ì¶œì²˜ í‘œí˜„ ê³¼ë‹¤")
        if scores["balance_and_objectivity"] < 0.4:
            weaknesses.append("í¸í–¥ëœ ì‹œê°")
        if scores["fact_verification"] < 0.4:
            weaknesses.append("ê²€ì¦ë˜ì§€ ì•Šì€ ì£¼ì¥ í¬í•¨")
        if scores["analysis_depth"] < 0.4:
            weaknesses.append("í”¼ìƒì ì¸ ì •ë³´ ì „ë‹¬")
        
        return weaknesses
    
    def _generate_recommendations(self, scores: Dict[str, float]) -> List[str]:
        """ê°œì„  ê¶Œê³ ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if scores["evidence_quality"] < 0.6:
            recommendations.append("ë” ë§ì€ í†µê³„, ì—°êµ¬ ê²°ê³¼, ê³µì‹ ë°œí‘œ ì¸ìš© í•„ìš”")
        if scores["source_transparency"] < 0.6:
            recommendations.append("ìµëª… ì¶œì²˜ë³´ë‹¤ ì‹¤ëª… ì¶œì²˜ í™œìš© ê¶Œì¥")
        if scores["balance_and_objectivity"] < 0.6:
            recommendations.append("ë‹¤ì–‘í•œ ì´í•´ê´€ê³„ìì˜ ì…ì¥ í¬í•¨ í•„ìš”")
        if scores["fact_verification"] < 0.6:
            recommendations.append("ì£¼ì¥ì— ëŒ€í•œ ê·¼ê±° ìë£Œ ë§í¬ ì¶”ê°€ í•„ìš”")
        if scores["analysis_depth"] < 0.6:
            recommendations.append("ë‹¨ìˆœ ì‚¬ì‹¤ ì „ë‹¬ì„ ë„˜ì–´ ì˜ë¯¸ì™€ ì˜í–¥ ë¶„ì„ í•„ìš”")
        
        return recommendations